{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"PEST++V3_cover.jpeg\" style=\"float: left\">\n",
    "\n",
    "<img src=\"flopylogo.png\" style=\"float: right\">\n",
    "\n",
    "<img src=\"AW&H2015.png\" style=\"float: center\">\n",
    "\n",
    "# History match the Freyberg model using a single ``K`` parameter\n",
    "\n",
    "Freyberg (1988) was notable for the discussing what is often called \"point calibration\" and \"overfitting\". It is a heterogenous 2D areal (1-layer) model that is a step up in complexity from our xsec model. Recall it looks like this, as shown in the original Freyberg (1988) paper on the left, and a Groundwater Vistas version on the right (from the file in the GW_Vistas subdirectory).   \n",
    "\n",
    "<img src=\"Freburg1988_fig1.png\" style=\"float: left\">\n",
    "<img src=\"Freyberg_k_plot_GW_Vistas.png\" style=\"float: right\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## As we discussed in our first notebook, one way to get to an optimal model is to start simple and add complexity. To do this right we need to add our forecasts first along with the calibration targets, and look at both as more model complexity is added.  One of the findings of the Freyberg (1988) model is that some students made their model too complex, which diminished its performance for the prediction of interest. Starting simple will keep us out of danger (at least for this notebook). \n",
    "\n",
    "This version of the Freyberg model has 3 stress periods:  1 steady state -> 1 transient for 10 years -> 1 steady state\n",
    "\n",
    "The river stage and node conductance changes in each stress period (see .sfr file)\n",
    "\n",
    "The recharge starts out wetter in stress period one, then is drier in stress periods 2 and 3 (see .rch file)\n",
    "\n",
    "Pumping well discharge changes each stress period (see .wel file)\n",
    "\n",
    "In addition to heads and fluxes, MODPATH is also included in the PEST++ model run file to perform particle tracking after MODFLOW finishes\n",
    "\n",
    "***********************************************\n",
    "__So, the objectives of this notebook are to:__\n",
    "\n",
    "1) Ease you into the Freyberg model as we'll be using it for the rest of the class\n",
    "\n",
    "2) Revisit the PEST control (pst) file\n",
    "\n",
    "3) Look at typical summary statistics and plots the describe our degree of fit\n",
    "\n",
    "4) Look at how head data constraints ripple to different forecast types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard two blocks to prep the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pyemu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import freyberg_setup as fs\n",
    "pst_name = fs.PST_NAME_UN\n",
    "working_dir = fs.WORKING_DIR_UN\n",
    "fs.setup_pest_un()\n",
    "pst = pyemu.Pst(os.path.join(working_dir,pst_name))\n",
    "pst.control_data.noptmax = 0\n",
    "pst.observation_data.loc[pst.observation_data.obgnme=='calflux', 'weight']=0\n",
    "\n",
    "pst.write(os.path.join(working_dir,pst_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs.plot_model(working_dir, pst_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We've given you all the files you need to run PEST++ on this model.  \n",
    "\n",
    "### Open up the .pst file, and orient yourself using to the PDF file \"Annotated_PEST_control_file_SIR20105169.pdf\".  We've highlighted the PEST variables that you are likely to manipulate; *NOTE: that unless something is in [brackets] a value must be supplied, but the default values you see in our example .pst files will be fine.*  \n",
    "\n",
    "### To guide your eyes through the PEST control file, answer these questions:\n",
    "\n",
    "1) How many parameters are we running? \n",
    "\n",
    "2) How many are adjustable? \n",
    "\n",
    "3) How many types of observations are included?\n",
    "\n",
    "4) How many forecasts? What types?\n",
    "\n",
    "5) How many template (tpl) files do we have?\n",
    "\n",
    "6) How many instruction (ins) files do we have? \n",
    "\n",
    "\n",
    "#### Here's an annotated top of the PEST control file from SIR 2010-5169:\n",
    "\n",
    "<img src=\"2010-5169_annotated_Appendix1_PST_file.png\" style=\"float: center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now that you know the .ins, and .tpl files, open them in a text editor (make sure you are looking at the ones in /activities/freyberg_un subdirectory). In a seperate terminal window, run TEMPCHEK, INSCHEK and PESTCHEK on the files we've given you. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Okay, you've got running PEST utilities in a separate terminal window by now?  To speed things up we've given you a way to execute these utilities from within the Freyberg notebook.  We've included the equivalent version of what you just did in the next three code blocks.  Execute the code block then look at terminal window where you launched this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use pyemu to run a command line, run tempchek on the tpl file listed\n",
    "pyemu.helpers.run(\"tempchek hk_layer_1.ref.tpl\",cwd=working_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use pyemu to run a command line, run inschek on the ins file listed\n",
    "pyemu.helpers.run(\"inschek flux.dat.ins flux.dat\",cwd=working_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use pyemu to run a command line, run inschek on the ins file listed\n",
    "pyemu.helpers.run(\"inschek freyberg.hyd.bin.dat.ins freyberg.hyd.bin.dat\",cwd=working_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Whoa - lots of heads!  Observations don't cost us any runs/computer time, so from now on we'll be carrying many more observations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use pyemu to run a command line, run inschek on the ins file listed\n",
    "pyemu.helpers.run(\"inschek freyberg.travel.ins freyberg.travel\",cwd=working_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use pyemu to run a command line, run inschek on the ins file listed\n",
    "pyemu.helpers.run(\"inschek vol.dat.ins vol.dat\",cwd=working_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use pyemu to run a command line, run pestchek on the pst file defined with pst during the import above\n",
    "pyemu.helpers.run(\"pestchek {0}\".format(pst_name),cwd=working_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Okay, let's run this thing. \n",
    "\n",
    "## Because we call a program from within the Jupyter Notebook you have to look at the terminal window that you used to start the notebook to see the screen report of the run.  So, when executing this next block look at your terminal window to see the run.  It will say \"Simulation complete...\" when finished.\n",
    "\n",
    "### NOTE:  And/or wait until the standard out  reports a \"0\" below this next block (=when the run is finished) before going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use pyemu to run a command line, run pestpp on the pst file defined on the import\n",
    "pyemu.helpers.run(\"pestpp {0} \".format(pst_name),cwd=working_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ``PEST++`` only ran the model one time - why?\n",
    "\n",
    "Yeah, that's right, the NOPTMAX=0 thing again.  We had that set to zero because we want to check the plumbing before burning the silicon. Did everything run (i.e., did you see \"Simulation Complete...\" in your terminal window?  Like before, you *could* change NOPTMAX to 20 in a text editor.  But, pyemu can do it for you with the next block.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define pst to be all the pest-type things of the *.pst file defined above by pst_name\n",
    "pst = pyemu.Pst(os.path.join(working_dir,pst_name))\n",
    "# have pyemu change PEST's NOPTMAX variable to 20\n",
    "pst.control_data.noptmax = 20\n",
    "# write out a new pst control file\n",
    "pst.write(os.path.join(working_dir,pst_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \"Trust but verify\"....by running PESTCHEK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use pyemu to run a command line, run pestchek on the pst file defined above\n",
    "pyemu.helpers.run(\"pestchek {0} \".format(pst_name),cwd=working_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOPTMAX=0 warning is gone. Now we let's run it.  Just like before  you have to look at the terminal window that you used to start the notebook to see the screen report of the run.  So, when executing this next block look at your terminal window to see the run.  It will say \"Simulation complete...\" when finished.\n",
    "\n",
    "Or wait until the standard out  reports a \"0\" below this next block (=when the run is finished) before going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use pyemu to run a command line, run pest++ on the pst file defined above\n",
    "pyemu.helpers.run(\"pestpp {0} \".format(pst_name),cwd=working_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's explore the results\n",
    "\n",
    "First let's look at the measurement objective function (Phi), which is calculated using the sum of squared weighted residuals.  First we'll look at a table, then plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a dataframe \"df_obj\" that shows the contents of the pst file casename with the extension .iobj\n",
    "# .iobj = PEST++ output file that has the objective function by iteration \n",
    "df_obj = pd.read_csv(os.path.join(working_dir,pst_name.replace(\".pst\",\".iobj\")),index_col=0)\n",
    "# echo out the dataframe\n",
    "df_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot out the dataframe that was shown as a table above\n",
    "df_obj.loc[:,[\"total_phi\",\"model_runs_completed\"]].plot(subplots=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at the FINAL OPTIMISATION RESULTS in the terminal where PEST++ ran (you can also find it near the bottom of the .rec file).  Which target group(s) matter?  How was splitting the contributions to PHI accomplished in the PEST control file?\n",
    "\n",
    "For this problem, recall our objective function is calculated using this equation:\n",
    "\n",
    "\n",
    "<img src=\"SOSWR_eq_AW&H2015.png\" style=\"float: center\">\n",
    "\n",
    "where Phi is the \"sum of squared weighted residuals\" that we look to minimize, *whi* is the weight for the ith head observation; *hm* is the measured (observed) head target; *hs* is the simulated head; and n is the number of observations.  If we use only heads for calibration the PHI only reflects the sum of squared weighted residuals for the observed-simulated head targets. \n",
    "\n",
    "# Hey, we told PEST to try 20 parameter estimation upgrades but it stopped at 3!  What gives?!?\n",
    "\n",
    "(hint: search the .rec file for OPTIMIZATION COMPLETE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PEST and PEST++ will quit the parameter estimation process if one of these 4 conditions is met:\n",
    "\n",
    "1) The maximum number of interations specified in NOPTMAX is reached\n",
    "\n",
    "2) The fit is not getting any better based on a user-supplied closure\n",
    "\n",
    "3) The parameters are not changing based on a user-supplied closure\n",
    "\n",
    "4) The user killed the run, usually with a ctrl-c  (happens quite frequently)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Let's evaulate our fit using the observed-simulated residuals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define pst to be all the pest-type things of the *.pst file defined above by pst_name\n",
    "pst = pyemu.Pst(os.path.join(working_dir,pst_name))\n",
    "# define res_nz to equal a table of residuals for all observations with non-zero weight\n",
    "res_nz = pst.res.loc[pst.nnz_obs_names,:]\n",
    "# echo out res_nz\n",
    "res_nz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use pyemu's plot utilities to plot 1:1 line and the residuals as fxn of observation magnitude\n",
    "pyemu.plot_utils.res_1to1(pst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Not too shabby!  Thanks PEST++.\n",
    "\n",
    "### These plots you'll see a lot.  The left plot is a \"1:1\" plot that has simulated on the x-axis and observed on the y-axis; a perfect fit would be all circles on the black diagonal line.  The right plot has the residual (y-axis) compared to the observation magnitude (x-axis).  The closer the circle is to the black line the better the fit.  The mean residual is shown as a red line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### But we had a lot of other observations listed in the PEST control file.  What do they look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define pst to be all the pest-type things of the *.pst file defined above by pst_name\n",
    "pst = pyemu.Pst(os.path.join(working_dir,pst_name))\n",
    "# echo out all the residuals, non-zero weight and zero weight\n",
    "pst.res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our naming convention:  Observations with 1970 in them represent the calibration period; those with 1975 represent the forecast period.  The last column is the weight given to them in the parameter estimation. \n",
    "\n",
    "# Now let's look at what the calibration did for uncertainty reduction\n",
    "\n",
    "### First, let's look the change in uncertainty for our one horizontal hydraulic conductivity (Kh) parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a dataframe that has uses the PEST++ output file freyberg_un.par.usum.csv\n",
    "# freyberg_un.par.usum.csv is comma-delimited file that has the uncertainty summary for the parameters\n",
    "df_paru = pd.read_csv(os.path.join(working_dir,pst_name.replace(\".pst\",\".par.usum.csv\")),index_col=0)\n",
    "# echo out this dataframe \n",
    "df_paru"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Things to Note: \n",
    "\n",
    "#### 1) Recall that because we log transformed the Kh parameter the uncertainty results are reported as logarithms in the dataframe above.  What you'll see in the MODFLOW input file is the non-log transformed Kh value, which is 10^0.69897 = 5.0 (prior mean) or 10^0.822663 = 6.65 (posterior mean)\n",
    "\n",
    "#### 2) Quick way to evaluate the *reduction in uncertainty* is to compare prior_stdev (=standard deviation of the prior=standard deviation before calibration) to post_stdev (=standard deviation of the posterior = standard deviation after caibration).  The amount that post_stdev is less than pre_stdev reflects the magnitude of the uncertainty reduction\n",
    "\n",
    "## Now let's plot it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a set of plots called ax to have the information of our dataframe df_paru above\n",
    "ax = pyemu.helpers.plot_summary_distributions(df_paru,label_post=True)\n",
    "# Plot it with a label \n",
    "ax.set_xlabel(\"$log_{10}(\\\\frac{L}{T})$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The dotted gray line represents the \"prior\" information as expressed by the parameter bounds in the PEST control file.  The shaded area is the uncertainty after the calibration.\n",
    "\n",
    "Why is porosity as uncertain after calibration as before calibration?\n",
    "\n",
    "\n",
    "\n",
    "# Now let's look at changes in model forecast uncertainty, first as a table then as a plot.  These are *observations* now instead of parameters like above....\n",
    "\n",
    "(To make it easier to identify the forecasts of interest we used the observation group \"forecast\" in the PEST control file - this is not mandatory but for convenience.  What makes something a forecast as far as PEST++ is concerned is the ++forecasts line in the PEST control file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a dataframe that has uses the PEST++ output file freyberg_un.pred.usum.csv\n",
    "# freyberg_un.pred.usum.csv is comma-delimited file that has the uncertainty summary for the predictions \n",
    "df_predu = pd.read_csv(os.path.join(working_dir,pst_name.replace(\".pst\",\".pred.usum.csv\")),index_col=0)\n",
    "# echo out the dataframe\n",
    "df_predu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same deal as above: the Quick way to evaluate the *reduction in uncertainty* is to compare prior_stdev (=standard deviation of the prior=standard deviation before calibration) to post_stdev (=standard deviation of the posterior = standard deviation after caibration).  The amount that post_stdev is less than pre_stdev reflects the magnitude of the uncertainty reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the pyemu plotting utility to plot up the forecasts\n",
    "figs, axes = pyemu.helpers.plot_summary_distributions(df_predu,subplots=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And  by comparing prior to posterior standard deviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for forecast in df_predu.index:\n",
    "    ax = df_predu.loc[forecast,[\"prior_stdev\",\"post_stdev\"]].plot(kind=\"bar\")\n",
    "    ax.set_title(forecast)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wow!  The calibration really reduced the uncertainty in our forecasts! So we can call it a day and bill the client?\n",
    "\n",
    "### Hmm, maybe not yet...the reductions look suspiciously similar.  Let's use a summary statistic, percent reduction in uncertainty, to help be quantitative on the reduction in forecast uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predu.loc[:,\"percent_reduction\"] = 100.0 * (1.0 - (df_predu.post_stdev / df_predu.prior_stdev))\n",
    "df_predu.percent_reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Does it make sense that the uncertainty for the flux targe would be reduced in the same proportion as the head forecasts?\n",
    "\n",
    "## Just for fun, and because we can, let's look again at forecast uncertainty with the \"truth\"..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figs, axes = pyemu.helpers.plot_summary_distributions(df_predu,subplots=True)\n",
    "for ax in axes:\n",
    "    fname = ax.get_title().lower()\n",
    "    ylim = ax.get_ylim()\n",
    "    v = pst.observation_data.loc[fname,\"obsval\"]\n",
    "    ax.plot([v,v],ylim,\"k--\")\n",
    "    ax.set_ylim(ylim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uh oh!  Why are some forecasts not bracketed by the posterior distribution? This means uncertainty analysis \n",
    "\n",
    "# \"failed\"! \n",
    "\n",
    "### The dashed line of the uncalibrated model (what we call the \"Prior\") actually encompasses the truth thus is more reliable than our calibrated model - why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
