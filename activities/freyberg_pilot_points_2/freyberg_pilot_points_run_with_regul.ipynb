{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Freyberg pilot points to use regularization and see what happens...\n",
    "\n",
    "### With our first attempt at pilot points, we saw bad things.  So lets see if we can fix the problem by using regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os, shutil\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import numpy as np\n",
    "from IPython.display import Image\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import flopy as flopy\n",
    "import pyemu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import freyberg_setup as fs\n",
    "fs.setup_pest_pp()\n",
    "working_dir = fs.WORKING_DIR_PP\n",
    "pst_name = fs.PST_NAME_PP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs.plot_model(working_dir, pst_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst = pyemu.Pst(os.path.join(working_dir,pst_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In the ``intro_to_regularization``, we talked about two common forms of regularization.  Here we will add both types to the control file.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, let's add a few preferred value equations for the recharge and well flux parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.parameter_data.pargp.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyemu.helpers.zero_order_tikhonov(pst,par_groups=[\"rch\",\"w0\",\"w1\"])\n",
    "#pyemu.helpers.zero_order_tikhonov(pst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.prior_information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, let's add preferred difference regularization to the spatially distributed parameters - more geostatistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = pyemu.geostats.ExpVario(contribution=1.0,a=2500.0)\n",
    "gs = pyemu.geostats.GeoStruct(variograms=v,nugget=0.0)\n",
    "df_pp = pyemu.gw_utils.pp_tpl_to_dataframe(os.path.join(working_dir,\"hkpp.dat.tpl\"))\n",
    "cov = gs.covariance_matrix(df_pp.x,df_pp.y,df_pp.parnme)\n",
    "pyemu.helpers.first_order_pearson_tikhonov(pst,cov,reset=False,abs_drop_tol=0.1)\n",
    "pst.prior_information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we need to adjust the inputs to pest the control how regularization is enforced.  The big knob is ``phimlim``.  But first, we need to change the estimation mode to \"regularization\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.control_data.pestmode = \"regularization\"\n",
    "pst.reg_data.phimlim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### That's no good - way too low - just a \"placeholder\" value.  Theoritically, it should be the number of non-zero weighted obs, but we saw in the unregularized pilot point run, are best ``phi`` was about 180, so let's try 220 (just a guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.reg_data.phimlim = 220\n",
    "pst.reg_data.phimaccept = 240\n",
    "#pst.svd_data.maxsing = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.write(os.path.join(working_dir,pst_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "os.chdir(working_dir)\n",
    "pyemu.helpers.start_slaves('.',\"pestpp\",pst_name,num_slaves=15,master_dir='.')\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(working_dir)\n",
    "pst.parrep(pst_name.replace(\".pst\",\".parb\"))\n",
    "pst.write_input_files()\n",
    "pyemu.gw_utils.fac2real(\"hkpp.dat\",factors_file=\"hkpp.dat.fac\",out_file=\"hk_layer_1.ref\")\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.plot(kind=\"phi_progress\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.plot(kind=\"1to1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's see how the parameter values look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_paru = pd.read_csv(os.path.join(working_dir,pst_name.replace(\".pst\",\".par.usum.csv\")),index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hk_pars = [p.upper() for p in pst.par_names if p.startswith(\"hk\")]\n",
    "df_hk = df_paru.loc[hk_pars,:]\n",
    "ax = pyemu.helpers.plot_summary_distributions(df_hk,label_post=True)\n",
    "mn = np.log10(pst.parameter_data.loc[hk_pars[0].lower(),\"parlbnd\"])\n",
    "mx = np.log10(pst.parameter_data.loc[hk_pars[0].lower(),\"parubnd\"])\n",
    "ax.plot([mn,mn],ax.get_ylim(),\"k--\")\n",
    "ax.plot([mx,mx],ax.get_ylim(),\"k--\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Not a good sign...lots of parameters are still at their bounds...not as many, but still a lot of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pp = pyemu.gw_utils.pp_tpl_to_dataframe(os.path.join(working_dir,\"hkpp.dat.tpl\"))\n",
    "m = flopy.modflow.Modflow.load(fs.MODEL_NAM,model_ws=working_dir)\n",
    "ax = m.upw.hk[0].plot(colorbar=True,alpha=0.5)\n",
    "ax.scatter(df_pp.x,df_pp.y,marker='x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.upw.hk[0] = os.path.join(fs.BASE_MODEL_DIR,\"hk.truth.ref\")\n",
    "ax = m.upw.hk[0].plot(colorbar=True,alpha=0.5)\n",
    "ax.scatter(df_pp.x,df_pp.y,marker='x')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "oh no!!!!!  We are still over fit...so let's back off the fit using ``phimilim``.  But first, just for fun, let's look at the forecast uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_foreu = pd.read_csv(os.path.join(working_dir,pst_name.replace(\".pst\",\".pred.usum.csv\")),index_col=0)\n",
    "figs, axes = pyemu.helpers.plot_summary_distributions(df_foreu,subplots=True)\n",
    "for ax in axes:\n",
    "    fname = ax.get_title().lower()\n",
    "    ylim = ax.get_ylim()\n",
    "    v = pst.observation_data.loc[fname,\"obsval\"]\n",
    "    ax.plot([v,v],ylim,\"b--\")\n",
    "    ax.set_ylim(ylim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are crushing the posterior uncertainty - it is considerable less than the prior for several forecasts. But, compared to the \"truth\", we are not doing well - the model is not reliable for many forecasts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adjust ``phimlim`` and rerun..\n",
    "\n",
    "Let's adjust the weights and ``phimlim`` based on how well we fit last time...and see if we can eliminate our overfitting problem.  How will we know we have eliminated it? In the real world, we will never know..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pst = pyemu.Pst(os.path.join(working_dir,pst_name))\n",
    "pst.res.loc[pst.nnz_obs_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.reg_data.phimlim = 500.0\n",
    "pst.reg_data.phimaccept = 550.0\n",
    "pst.reg_data.fracphim = 0.75\n",
    "pst.svd_data.maxsing = 3\n",
    "pst.write(os.path.join(working_dir,pst_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(working_dir)\n",
    "pyemu.helpers.start_slaves('.',\"pestpp\",pst_name,num_slaves=15,master_dir='.')\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(working_dir)\n",
    "pst.parrep(pst_name.replace(\".pst\",\".parb\"))\n",
    "pst.write_input_files()\n",
    "pyemu.gw_utils.fac2real(\"hkpp.dat\",factors_file=\"hkpp.dat.fac\",out_file=\"hk_layer_1.ref\")\n",
    "os.chdir(\"..\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.plot(kind=\"phi_progress\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst = pyemu.Pst(os.path.join(working_dir,pst_name))\n",
    "pst.phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.plot(kind=\"1to1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = flopy.modflow.Modflow.load(fs.MODEL_NAM,model_ws=working_dir)\n",
    "ax = m.upw.hk[0].plot(colorbar=True,alpha=0.5)\n",
    "ax.scatter(df_pp.x,df_pp.y,marker='x')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "That's much better..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.upw.hk[0] = os.path.join(fs.BASE_MODEL_DIR,\"hk.truth.ref\")\n",
    "ax = m.upw.hk[0].plot(colorbar=True,alpha=0.5)\n",
    "ax.scatter(df_pp.x,df_pp.y,marker='x')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see how the uncertainty looks..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst = pyemu.Pst(os.path.join(working_dir,pst_name))\n",
    "pst.phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_paru = pd.read_csv(os.path.join(working_dir,pst_name.replace(\".pst\",\".par.usum.csv\")),index_col=0)\n",
    "hk_pars = [p.upper() for p in pst.par_names if p.startswith(\"hk\")]\n",
    "df_hk = df_paru.loc[hk_pars,:]\n",
    "ax = pyemu.helpers.plot_summary_distributions(df_hk,label_post=True)\n",
    "mn = np.log10(pst.parameter_data.loc[hk_pars[0].lower(),\"parlbnd\"])\n",
    "mx = np.log10(pst.parameter_data.loc[hk_pars[0].lower(),\"parubnd\"])\n",
    "ax.plot([mn,mn],ax.get_ylim(),\"k--\")\n",
    "ax.plot([mx,mx],ax.get_ylim(),\"k--\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahh yeah!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figs, axes = pyemu.helpers.plot_summary_distributions(os.path.join(working_dir,\n",
    "                    pst_name.replace(\".pst\",\".pred.usum.csv\")),subplots=True)\n",
    "for ax in axes:\n",
    "    fname = ax.get_title()\n",
    "    pyemu.helpers.plot_summary_distributions(df_foreu.loc[[fname],:],ax=ax,pt_color='g')\n",
    "    fname = fname.lower()\n",
    "    ylim = ax.get_ylim()\n",
    "    v = pst.observation_data.loc[fname,\"obsval\"]\n",
    "    ax.plot([v,v],ylim,\"b--\")\n",
    "    ax.set_ylim(ylim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now bracketing the \"truth\" with significant probability for most forecast (FINALLY!!!). So, even though we aren't fitting the observations as well (hence posterior uncertainty), we are doing much better from a reliability stand point. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
