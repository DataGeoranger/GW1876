{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Freyberg pilot points to use regularization and see what happens...\n",
    "\n",
    "### With our first attempt at pilot points, we saw bad things.  So lets see if we can fix the problem by using regularization.\n",
    "\n",
    "Recall from Anderson et al. (2015) regularization adds an additional term to our total objective function:\n",
    "\n",
    "<img src=\"tik-reg_eq9.9.png\" style=\"float: center\">\n",
    "\n",
    "The first term to the right of the equals sign is the measurement objective function from\n",
    "Eqn (9.6), which is calculated as the sum of squared weighted residuals, where *n* residuals,\n",
    "*ri*, are calculated from hard knowledge and wi are their respective weights. The second\n",
    "term quantifies the penalty resulting from deviations from soft knowledge as the sum\n",
    "of *q* deviations from *j* soft knowledge conditions *fj*, where *fj* is a function of model parameters\n",
    "*p*. \n",
    "\n",
    "## A calibrated model, therefore, is found by minimizing both the measurement objective function (hard data) and the soft knowledge penalty.\n",
    "\n",
    "\n",
    "### Let's see how to do this in PEST\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os, shutil\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import numpy as np\n",
    "from IPython.display import Image\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import flopy as flopy\n",
    "import pyemu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import freyberg_setup as fs\n",
    "fs.setup_pest_pp()\n",
    "working_dir = fs.WORKING_DIR_PP\n",
    "pst_name = fs.PST_NAME_PP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs.plot_model(working_dir, pst_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Okay, we have a running PEST setup and model to work with - let's use a shortcut variable to tell pyemu that we want interrogate or look at this particular model.... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst = pyemu.Pst(os.path.join(working_dir,pst_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In the ``intro_to_regularization``, we talked about two common forms of Tikhonov regularization.  Here we will add both types to the control file.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, let's add a few preferred value equations for the recharge and well flux parameters.  First, let's use pyemu to tell us what parameter groups are in our PEST control file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# echo out what parameter groups are in the PEST control file\n",
    "pst.parameter_data.pargp.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See the pst at the beginning of the line of code?  That is the variable we defined above that has the PEST control file specified.  That is how pyemu knows which model to report on.\n",
    "\n",
    "### Even more power than echoing out what is in the PEST files, we can use pyemu to add preferred value regularization equations to the recharge and well parameter groups.  Note though, pyemu doesn't call it \"preferred value\"! Rather, it uses the mathematical term \"Zero Order Tikhonov\" so we have to use that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use pyemu to apply preferred value (aka zero order Tikhonov) to the parameters at the end\n",
    "pyemu.helpers.zero_order_tikhonov(pst,par_groups=[\"rch\",\"w0\",\"w1\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note that only recharge and well parameters were regularized (i.e., the ones listed at the end of the line of code).\n",
    "\n",
    "##### Let's see how the preferred value equation looks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.prior_information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RECALL:  This report does not mean that the PEST control file has been updated! It is simply reporting what is in pyemu's memory block.\n",
    "\n",
    "\n",
    "### Now, let's add preferred difference regularization to the spatially distributed parameters.  Note that preferred value only needed one parameter (the value of that parameter).  A preferred difference regularization constraint involves 2 parameters.  But the spatial distance between any two parameters is not the same - how do we deal?  With  geostatistics! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = pyemu.geostats.ExpVario(contribution=1.0,a=2500.0)\n",
    "gs = pyemu.geostats.GeoStruct(variograms=v,nugget=0.0)\n",
    "df_pp = pyemu.pp_utils.pp_tpl_to_dataframe(os.path.join(working_dir,\"hkpp.dat.tpl\"))\n",
    "cov = gs.covariance_matrix(df_pp.x,df_pp.y,df_pp.parnme)\n",
    "pyemu.helpers.first_order_pearson_tikhonov(pst,cov,reset=False,abs_drop_tol=0.1)\n",
    "pst.prior_information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note that the preferred difference = 0, which means our preferred difference regularization is really a preferred *homogeneity* condition!\n",
    "\n",
    "\n",
    "\n",
    "### Okay, getting close.  Some housekeeping - we need to change PEST's estimation mode from \"estimation\" to \"regularization\".  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.control_data.pestmode = \"regularization\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## And, most importantly we need to see what pyemu has for the all important regularization BIG KNOB, the target objective function - or ``phimlim``.  This is THE ONE INPUT that tells PEST how regularization is enforced.  So let's use pyemu to see what our control file has for ``phimlim``.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the PEST control file defined by pst above, echo out phimlim\n",
    "pst.reg_data.phimlim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### That's no good - way too low for a final parameter estimation.  But recall our workflow from the Intro to Regularization workbook.  Thisd is just a \"placeholder\" value to ignore soft knowledge and only focus on the best fit.  After the how-low-can-PEST-go run, ``phimlim`` should be set to a larger number, say the number of non-zero weighted obs.  Here we'll explore the effect of ``phimlim`` a bit.  We saw in the unregularized pilot point run, are best ``phi`` was about 120, so let's try doubling that to 240 (just a guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use pyemu to set the phimlim to 240\n",
    "pst.reg_data.phimlim = 240\n",
    "# when phimlim changes so should phimaccept, and is usually 5-10% higher than phimlim\n",
    "pst.reg_data.phimaccept = 260\n",
    "#pst.svd_data.maxsing = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we're ready to write all the information that pyemu has in memory to the PEST control file...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.write(os.path.join(working_dir,pst_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You can look at the file we just wrote by opening freyberg_pp.pst in the freyberg_pp directory, but here we'll plunge on.  Let's run it - this will again take a little time, watch the run in the terminal window that launched the notebook...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "os.chdir(working_dir)\n",
    "pyemu.helpers.start_slaves('.',\"pestpp\",pst_name,num_slaves=15,master_dir='.')\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Okay - let's look at how we did"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the reduction of phi by model runs\n",
    "pst.plot(kind=\"phi_progress\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# report the final phi for the PEST run defined in pst\n",
    "pst.phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the results\n",
    "pst.plot(kind=\"1to1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's see how the parameter values look.  First, let's take the optimal parameter values from our run and put them through fac2real to make arrays...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(working_dir)\n",
    "pst.parrep(pst_name.replace(\".pst\",\".parb\"))\n",
    "pst.write_input_files()\n",
    "pyemu.geostats.fac2real(\"hkpp.dat\",factors_file=\"hkpp.dat.fac\",out_file=\"hk_layer_1.ref\")\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let's plot it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_paru = pd.read_csv(os.path.join(working_dir,pst_name.replace(\".pst\",\".par.usum.csv\")),index_col=0)\n",
    "\n",
    "hk_pars = [p.upper() for p in pst.par_names if p.startswith(\"hk\")]\n",
    "df_hk = df_paru.loc[hk_pars,:]\n",
    "ax = pyemu.plot_utils.plot_summary_distributions(df_hk,label_post=True)\n",
    "mn = np.log10(pst.parameter_data.loc[hk_pars[0].lower(),\"parlbnd\"])\n",
    "mx = np.log10(pst.parameter_data.loc[hk_pars[0].lower(),\"parubnd\"])\n",
    "ax.plot([mn,mn],ax.get_ylim(),\"k--\")\n",
    "ax.plot([mx,mx],ax.get_ylim(),\"k--\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Not a good sign...lots of parameters are still at their bounds (dashed vertical black lines)...not as many, but still a lot of them.  Let's see what the optimal field look likes...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pp = pyemu.pp_utils.pp_tpl_to_dataframe(os.path.join(working_dir,\"hkpp.dat.tpl\"))\n",
    "m = flopy.modflow.Modflow.load(fs.MODEL_NAM,model_ws=working_dir)\n",
    "ax = m.upw.hk[0].plot(colorbar=True,alpha=0.5)\n",
    "ax.scatter(df_pp.x,df_pp.y,marker='x')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Hmm, let's plot the true field again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.upw.hk[0] = os.path.join(fs.BASE_MODEL_DIR,\"hk.truth.ref\")\n",
    "ax = m.upw.hk[0].plot(colorbar=True,alpha=0.5)\n",
    "ax.scatter(df_pp.x,df_pp.y,marker='x')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oh no!!!!!  Better but we are still over fit...so let's back off the fit using ``phimilim``.  But first,  let's see how this overfit model did simulating the forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_foreu = pd.read_csv(os.path.join(working_dir,pst_name.replace(\".pst\",\".pred.usum.csv\")),index_col=0)\n",
    "figs, axes = pyemu.plot_utils.plot_summary_distributions(df_foreu,subplots=True)\n",
    "for ax in axes:\n",
    "    fname = ax.get_title().lower()\n",
    "    ylim = ax.get_ylim()\n",
    "    v = pst.observation_data.loc[fname,\"obsval\"]\n",
    "    ax.plot([v,v],ylim,\"b--\")\n",
    "    ax.set_ylim(ylim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We are doing well with the posterior uncertainty - the shaded area is thinner and higher than the grey dashed prior uncertainty for several forecasts. But, compared to the \"truth\" (vertical blue line), we are not doing well - the model is not reliable for all forecasts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adjust ``phimlim`` and rerun..\n",
    "\n",
    "### Let's adjust the weights and ``phimlim`` based on how well we fit last time...and see if we can eliminate our overfitting problem.  How will we know we have eliminated it? In the real world, we will never know...\n",
    "\n",
    "### Before changing, let's get a feel for what the model results look like with ``phimlim`` = 250.  So we said wanted our target objective function to be 250.  Where did it end up?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.phi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretty much where we should be, but our parameter fit wzs overfit. What does a Phi of around 250 look like for the observations? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pst = pyemu.Pst(os.path.join(working_dir,pst_name))\n",
    "pst.res.loc[pst.nnz_obs_names]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Okay, let's use pyemu to change PHIMLIM, let's double it to 500.  And the last line writes the new PEST control file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.reg_data.phimlim = 500.0\n",
    "pst.reg_data.phimaccept = 550.0\n",
    "pst.reg_data.fracphim = 0.75\n",
    "pst.svd_data.maxsing = 3\n",
    "pst.write(os.path.join(working_dir,pst_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  You can look at the bottom of freyberg_pp.pst to see the change we made, but let's start the run...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(working_dir)\n",
    "pyemu.helpers.start_slaves('.',\"pestpp\",pst_name,num_slaves=15,master_dir='.')\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's look at Phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.plot(kind=\"phi_progress\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst = pyemu.Pst(os.path.join(working_dir,pst_name))\n",
    "pst.phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.plot(kind=\"1to1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's look at the K field again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(working_dir)\n",
    "pst.parrep(pst_name.replace(\".pst\",\".parb\"))\n",
    "pst.write_input_files()\n",
    "pyemu.geostats.fac2real(\"hkpp.dat\",factors_file=\"hkpp.dat.fac\",out_file=\"hk_layer_1.ref\")\n",
    "os.chdir(\"..\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = flopy.modflow.Modflow.load(fs.MODEL_NAM,model_ws=working_dir)\n",
    "ax = m.upw.hk[0].plot(colorbar=True,alpha=0.5)\n",
    "ax.scatter(df_pp.x,df_pp.y,marker='x')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## That's much better...let's compare it to the truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.upw.hk[0] = os.path.join(fs.BASE_MODEL_DIR,\"hk.truth.ref\")\n",
    "ax = m.upw.hk[0].plot(colorbar=True,alpha=0.5)\n",
    "ax.scatter(df_pp.x,df_pp.y,marker='x')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let's see how the uncertainty looks..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_paru = pd.read_csv(os.path.join(working_dir,pst_name.replace(\".pst\",\".par.usum.csv\")),index_col=0)\n",
    "hk_pars = [p.upper() for p in pst.par_names if p.startswith(\"hk\")]\n",
    "df_hk = df_paru.loc[hk_pars,:]\n",
    "ax = pyemu.plot_utils.plot_summary_distributions(df_hk,label_post=True)\n",
    "mn = np.log10(pst.parameter_data.loc[hk_pars[0].lower(),\"parlbnd\"])\n",
    "mx = np.log10(pst.parameter_data.loc[hk_pars[0].lower(),\"parubnd\"])\n",
    "ax.plot([mn,mn],ax.get_ylim(),\"k--\")\n",
    "ax.plot([mx,mx],ax.get_ylim(),\"k--\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ahhh yeah! Lot fewer pilot points at the bounds.  What about the forecasts?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figs, axes = pyemu.plot_utils.plot_summary_distributions(os.path.join(working_dir,\n",
    "                    pst_name.replace(\".pst\",\".pred.usum.csv\")),subplots=True)\n",
    "for ax in axes:\n",
    "    fname = ax.get_title()\n",
    "    pyemu.plot_utils.plot_summary_distributions(df_foreu.loc[[fname],:],ax=ax,pt_color='g')\n",
    "    fname = fname.lower()\n",
    "    ylim = ax.get_ylim()\n",
    "    v = pst.observation_data.loc[fname,\"obsval\"]\n",
    "    ax.plot([v,v],ylim,\"b--\")\n",
    "    ax.set_ylim(ylim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Green shading is the previous run with PHIMLIM = 250; blue shading is the new run with PHIMLIM = 500.  The new run now brackets the \"truth\" with significant probability for most forecast (FINALLY!!!). So, even though we aren't fitting the observations as well, we are doing much better from a model forecast reliability stand point. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
