{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"AW&H2015.png\" style=\"float: left\">\n",
    "\n",
    "<img src=\"flopylogo.png\" style=\"float: center\">\n",
    "\n",
    "# Modifying PEST:  Adding an additional parameter to our cross sectional model\n",
    "\n",
    "The goal of model calibration is to find a model that has the best history match __while also__ using reasonable parameters.  In our manual trial-and-error and our PEST setup of the cross sectional model we had only one parameter hk1 = horizontal hydraulic conductivity for the aquifer. But, our cross-sectional model is simple - recall that it looked like this:\n",
    "\n",
    "<img src=\"xsect_figure.png\" style=\"float: center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So perhaps one parameter is all we need for a good forecast. Or perhaps not - how should we think of this?  In *Applied Groundwater Modeling (2nd edition)* by Anderson et al. (2015) we see that uncertainty in a model's forecast is directly related to the amount of simplicity/complexity that is brought to bear: \n",
    "\n",
    "<img src=\"Fig10.2_MML_curves.png\" style=\"float: center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that our model can be __too complex__ and make the model forecast more uncertain.  But less recognized, our model can also be __too simple__ and we can handcuff the model's ability to simulate the forecast thus in effect increasing uncertainty in the forecast. This tradeoff has been called the \"Goldilocks Principle\", or in economics, the \"law of Diminishing Returns\", which looks something like this:\n",
    "\n",
    "\n",
    "<img src=\"Hunt1998_sweetspot.png\" style=\"float: center\">\n",
    "\n",
    "\n",
    "Unfortunately too much complexity or oversimplification is not easy to recognize *a priori*.  During this class we'll look at both cases to help you identify the \"sweet spot\" for reduced uncertainty.\n",
    "\n",
    "In this notebook we won't perform the calculations as shown in figure 10.2. Rather, we'll take an easier \"proof-is-in-the-pudding\" approach:  we'll add another parameter to our cross-section model and see how much the forecast uncertainty changes. \n",
    "\n",
    "Why do it this way?  Because PEST++ has made it very easy to track forecast uncertainty for you, the approach we use here is the easiest way to evaluate model oversimplification.  And it focuses your attention on the __*forecast*__ which is why most models are built in the first place.  And it is straightforward as it only consists of:\n",
    "\n",
    " 1. Creating a quick and simple model, estimate uncertainty in your forecasts\n",
    " 2. Adding parameter(s), then evaluating changes in forecast uncertainties.\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Objectives:  \n",
    " \n",
    " 1) Add a new parameter to an existing PEST run by making a new template file\n",
    " \n",
    " 2) Update the PEST control file so it sees and knows what to do with the new parameter\n",
    " \n",
    " 3) See how forecast uncertainty can change as model complexity changes\n",
    " \n",
    " 4) Emphasize that what we do here is a great first step to better, more certain, model forecasts!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting back into the xsec cross-sectional model\n",
    "\n",
    "In the xsec_pest_setup exercise you noted the forecast uncertainty for h02_8, which is the head in the 8th node from the left calculated during the second stress period. Let's add another parameter and see what happens to the uncertainty in this forecast."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recall that the profile model looks like ths:\n",
    "\n",
    "<img src=\"xsect_figure.png\" style=\"float: center\">\n",
    "\n",
    "We'll make the flux boundary condition on the right side (the green node) a parameter.  By taking a parameter that is \"fixed\" (= not changed during parameter estimation) and making it adjustable, we increase the model complexity.  Again, first we'll do some Python notebook prep (push shift-enter in the next code block)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import shutil, os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First copy over the raw model files;  for this activity, we are providing the files you need.  This next block of code copies them to your */acitivities/xsec_k_and_flux* subdirectory for you.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "base_dir = os.path.join(\"..\",\"..\",\"models\",\"10par_xsec\",\"raw_model_files\")\n",
    "[shutil.copy2(os.path.join(base_dir,f),f) for f in os.listdir(base_dir)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Now we'll create another *template (.TPL)* file\n",
    "\n",
    "We are going to make the rightmost flux a parameter.  But, recall that our problem had __two__ stress periods, an initial calibration period followed by a forecast period:\n",
    "\n",
    "<img src=\"xsect_problem_fig1.png\" style=\"float: center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, there are __two__ boundary condition flux values, one for each stress period, that we need to make parameters. Why should we add a parameter for the second (future/forecast) stress period?\n",
    "\n",
    "The easiest way to make a template file is to modify an existing input file. A flux boundary condition is entered into MODFLOW using the WEL Package input file.  Also recall these steps from our xsec_pest_setup notebook: \n",
    "\n",
    " 1. Look inside __xsect_k_flux.pst__ to see which forward model is to be run. \n",
    " 2. It's MODFLOW, so read the NAM file to find the name of the WEL Package input file\n",
    " 3. Open the .wel file in a text editor\n",
    " 4. Make a copy of the input file and name it the same as the input file but with .tpl extension\n",
    " 5. Add a new line on top of your tpl file to tell PEST that it is a template file and what the delimiter is\n",
    " 6. Substitute the variable __sp1_flux__ and __sp2_flux__ surrounded by the delimiter you chose where appropriate\n",
    " 7. Save the file and run TEMPCHEK \n",
    "\n",
    "#### Reminder of the Rules for constructing TPL Files \n",
    "\n",
    " 1. The first line of the TPL file must identify that it is a template file by listing \"`ptf ~`\" where \"`~`\" is a \"parameter delimiter\" that tells PEST where a parameter sits in the file. We used a tilde here but it can be any symbol. __However__, whatever delimiter symbol is listed in the first line must be used consistently throughout that template file.\n",
    " 2. The template file looks like the original model input file __BUT__ parameters are substituted for the  model input(s) that we want PEST to estimate.  Parameters are identified by surrounding the parameter name listed in the PEST control (.pst) file with the delimiter.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How does PEST know that we created another Template file?\n",
    "\n",
    "### We have to __modify__ the PEST Control File.\n",
    "The PEST control file (.pst) is the main driver of the PEST run. It has most all of the important information needed to direct PEST, so it is a logical place to start. Recall that the top of the file has these PEST variables taken from Appendix 1 from SIR 2010-5169 we handed out:\n",
    "\n",
    "<img src=\"2010-5169_Appendix1_PST_file.png\" style=\"float: center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    " We have to modify the number of parameters (NPAR) because we are adding one (bcflux).  And because a flux parameter is different than hydraulic conductivity, we should add another parameter group (NPARGP).  \n",
    " \n",
    " 1. Open __xsect.pst__ in a text editor. \n",
    " 2. Increase NPAR by 2 (as we are adding two parameters)\n",
    " 3. Increase NPARGP by 1 (because both parameters are the same type)\n",
    " 4. Increase NTPLFILE by 1 (both parameters are in one new template file)\n",
    " \n",
    "We also have to give the information for this new parameter.  This is in the 'parameter groups' ( * parameter group) and 'parameter data' (* parameter data) sections further down in the PEST control file  (__Hint:__  The PEST input is more easily naviagated by searching for the * that demarcates a new PEST input section). \n",
    " \n",
    " <img src=\"2010-5169_Appendix1_PST_file_parameter.png\" style=\"float: center\">\n",
    " \n",
    " \n",
    "4. Make a new blank line below the existing line in * parameter groups\n",
    "5. Copy the line above into the new blank line\n",
    "6. Change the first entry in the line PARGPNME to a new parameter group name - let's use __fluxbc__\n",
    "\n",
    "now let's do something similar to add the parameter data:\n",
    "\n",
    "7. Make a new blank line below the existing line in * parameter data\n",
    "8. Copy the line above into the new blank line\n",
    "9. Change the first entry PARNME to match what you entered for a parameter name in your template file (__sp1_flux__)\n",
    "10. Change the initial value PARVAL1 to the value that was in the WEL input file (0.5)\n",
    "11. Change PARLBND to 0.0001 (this is the lower bound that PEST will use)\n",
    "12. Change PARUBND to 10000 (this is the upper bound that PEST will use)\n",
    "13. Change PARGP to match the parameter group name __fluxbc__\n",
    "14. Make a new blank line below this new line, copy the line we just created into the blank space\n",
    "15. In this second new line change (__sp1_flux__) to (__sp2_flux__)\n",
    "16. For __sp2_flux__, change PARVAL1 from 0.5 to 1.0 to match what was in the original .wel file\n",
    "\n",
    "Moreover, we have to tell PEST what is the name of the new template file, and what filename it should use when it creates the model input file.  That is done in the \"* model input/output section:\n",
    "\n",
    "<img src=\"2010-5169_Appendix1_PST_file_input_output.png\" style=\"float: center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so we need to:\n",
    "\n",
    "14. Add a blank line after the first line in the section that has the existing tpl file from the xsec_pest_setup exercise.\n",
    "15. Add the template file name (TEMPFLE variable), a space, then the model input file (INFILE variable) that we want PEST to create when it uses the template\n",
    "\n",
    "But we are not done yet with the PEST control file.  We've made a lot of changes to the file, and a small change to PEST setup, so we should do another NOPTMAX=0 run to test the plumbing.  \n",
    "\n",
    "16. Check if NOPTMAX in the 9th line of the control file = 0\n",
    "17. Add our forecast from last activity (add __++forecasts(h02_8)__ to the very bottom of the file)\n",
    "17. Save the PEST control file as xsec_k_flux.pst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whew - that is a lot of things to manipulate for just one additional template file!  But this flexibility is needed once we move to less trivial models.  And one can now really see the need for PESTCHEK! So,finally (!) run PESTCHEK at the command line by typing:  \n",
    "\n",
    "__pestchek xsec_k_flux.pst__  \n",
    "\n",
    "or \n",
    "\n",
    "__./pestchek xsec_k_flux.pst__ \n",
    "\n",
    "\n",
    "for Windows or Mac, respectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Digression:  \"Oh no - PESTCHEK didn't like my PEST control file!\"\n",
    "\n",
    "If you got an error don't take it personally, happens all the time (that is why John Doherty wrote PESTCHEK in the first place). Rather, take a deep breath and look at the PESTCHEK report: you'll see that PESTCHEK is very good at guiding your eyes to what needs fixing. Give it a go if you got an error - if you can't figure it out grab one of the instructors.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Now that we have our new template file and told PEST about it, let's run PEST++!\n",
    "\n",
    "When error free we can now focus on the PESTCHEK warning that the control file has `NOPTMAX=0`, which is what we want because the model only is run once, and then PEST++ processes all the output and reports the objective function phi. This checks that we have all the information flowing out of and back into PEST.  And, if we don't like the objective function distribution we can reweight, then re-run PEST++ with `NOPTMAX=0` again. \n",
    "\n",
    "### Run PEST++ on xsec_k_flux.pst \n",
    "\n",
    "__pest++ xsec_k_flux.pst__ (Windows) or __./pestpp xsec_k_flux.pst__ (Mac)\n",
    "\n",
    "\n",
    "Look at the `.rec` file to see results. See where your new template file information is echoed?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change NOPTMAX, re-run PEST++ on xsec_k_flux.pst\n",
    "\n",
    "Once we see that everything is plumbed as we had intended, open __xsec_k_flux.pst__ in a text editor and change NOPTMAX to 20, rerun PEST++. Look at the `.rec` file again to see results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Search for \"FINAL OPTIMISATION RESULTS\" in your rec file\n",
    "\n",
    "\n",
    "# What happened to our Calibration?\n",
    "\n",
    "Not much, our measurement objective function Phi is about the same good fit.\n",
    "\n",
    "\n",
    "# More importantly, what happened to our forecast uncertainty?   \n",
    "Was there a change in forecast uncertainty from increasing the number of parameters to 3?  Was the uncertainty larger or smaller?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's see if we can get back to where we were in xsect_pest_setup\n",
    "\n",
    "You can turn a parameter on and off, where \"on\" = adjustable and \"off\" = fixed or not adjustable.  Change  your __sp1_flux__  and __sp2_flux__ parameter from \"log\" to \"fixed\" in the PEST control file.  Save the file, rerun PESTCHEK and PEST++.  \n",
    "\n",
    "Did you get the same uncertainty for the forecast that you saved from the xsect_pest_setup activity?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now this next bit is important!\n",
    "PEST++ has made this forecast analysis very easy on you:\n",
    "\n",
    "__It used your lower and upper bounds to set the uncertainty around the parameters__ as it expects you view those bounds as a reasonable range of the parameter values.  But, we had you make the range very large.  Let's narrow the range to something more reasonable.  \n",
    "\n",
    "1) Open __xsect_k_flux.pst__ in a text editor,  and make all three parameter adjustable again\n",
    "\n",
    "2) change PARLBND to 0.1 and PARUBND to 2.0 for both __sp1_flux__ and __sp2_flux__, and save the file  \n",
    "\n",
    "3) Run PESTCHEK \n",
    "\n",
    "4) if no error rerun PEST++ on the file, and look at the change in the forecast uncertainty reported in the rec file.\n",
    "\n",
    "__Aside:__ When we estimate the uncertainty around our parameters before calibration it is called \"building our prior\". You'll hear a lot more about that this week.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the change in parameter uncertainty when the parameter bounds were tightened?  \n",
    "\n",
    "\n",
    "### And more to the point, was the forecast uncertainty for H02_8 larger or smaller?  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Now, let's make sure we know how uncertainty is reported:\n",
    "\n",
    "1) Open up your PEST control file __'xsect_k_flux.pst'__, find the \"parameter data\" section, and change the word \"none\" to \"log\".\n",
    "\n",
    "##### This log transforms the parameters, which is recommended for any parameter that should not go negative (like hydraulic conductivity). \n",
    "\n",
    "2) Run pestchek and PEST++ again\n",
    "\n",
    "3) Open up your __xsect_k_flux.rec__ file again and look at the bottom of the file.\n",
    "\n",
    "#### Hmm, the fit (as shown by the reported Phi) looks similar. Why is the prior mean of the parameter sp2_flux = 0!!  \n",
    "\n",
    "Is the forecast log or non-log tranformed?\n",
    "\n",
    "Did the forecast H02_8 and its uncertainty change when we log transformed the parameters?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hmm, did any of these changes effect what was reported for uncertainty around sp2_flux?  Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced - playing with fixing and freeing parameters and its effect on uncertainty \n",
    "\n",
    "Now explore the combinations of fixing and freeing  parameters. Rename and save the rec file after each run for comparison:\n",
    "\n",
    "1) __hk1__ and __sp1_flux__ adjustable; __sp2_flux__ fixed\n",
    "\n",
    "\n",
    "*where did sp2_flux go on the bottom of the rec file?*\n",
    "\n",
    "\n",
    "2) __sp1_flux__ adjustable; __hk1__ and __sp2_flux__ fixed\n",
    "\n",
    "3) __sp1_flux__ and __sp2_flux__ adjustable; __hk1__ fixed\n",
    "\n",
    "and most interestingly:\n",
    "\n",
    "4) __sp2_flux__ adjustable; __hk1__ and __sp1_flux__ fixed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**********"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Was the reported uncertainty larger when more parameters are included as we expect from the theory as shown in Figure 10.2 at the top of this notebook? \n",
    "\n",
    "### What is going on with combination 4 above?\n",
    "\n",
    "### Add the starting head at the left boundary a parameter as a parameter, change its bounds, and evaluate the change in forecast uncertainty.\n",
    "\n",
    "### One last parting thought:  We added one additional type of parameter, what *other* simplifications does our model have that may lead it to be oversimplified?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
