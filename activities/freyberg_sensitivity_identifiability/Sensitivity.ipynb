{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"PEST++V3_cover.jpeg\" style=\"float: left\">\n",
    "\n",
    "<img src=\"flopylogo.png\" style=\"float: right\">\n",
    "\n",
    "<img src=\"AW&H2015.png\" style=\"float: center\">\n",
    "\n",
    "# Looking at Parameter Sensitivity\n",
    "\n",
    "We have already discussed the Jacobian matrix in a few places. It is calculated by perturbing the parameter (usually 1%) and tracking what happens to each observation.  In a general form the sensitivity equation looks like eq. 9.7 Anderson et al. 2015:\n",
    "\n",
    "<img src=\"Sensitivity_eq.png\" style=\"float: center\">\n",
    "\n",
    "This is key for derivative-based parameter estimation because, as we've seen, this allows us to efficiently compute upgraded parameters to try during the lambda search.  But the Jacobian matrix can give us insight about the model in and of itself. \n",
    "\n",
    "Let's take a look at it more closely and see what we can learn from it and how to handle such information as the number of parameters rises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pyemu\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "runall_flag = False\n",
    "import sensitivity_identifiability_helper as sih"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bring in the model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import freyberg_setup as fs\n",
    "fs.setup_pest_kr()\n",
    "fs.setup_pest_pp()\n",
    "working_dir = fs.WORKING_DIR_KR\n",
    "pst_name = fs.PST_NAME_KR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First read in the PST file and find what are the starting values for K and R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inpst = pyemu.Pst(os.path.join(working_dir,pst_name))\n",
    "inpst.parameter_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's tell PEST++ to calculate the Jacobian matrix by changing NOPTMAX from 0 to -1 \n",
    "(recall NOPTMAX=-1 calculates the Jacobian but not all the statistics, which is NOPTMAX=-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inpst = pyemu.Pst(os.path.join(working_dir,pst_name))\n",
    "inpst.control_data.noptmax =  -1\n",
    "inpst.write(os.path.join(working_dir,pst_name.replace(\".pst\",\".final.pst\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's calculate the sensitivity by PEST++\n",
    "(recall a Jacobian matrix takes a minimum of NPAR + 1, which is 4 runs for this case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " pyemu.helpers.run(\"pestpp {0}\".format(pst_name.replace(\".pst\",\".final.pst\")),cwd=working_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We can also calculate one for a more complicated Pilot Points model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inpst = pyemu.Pst(os.path.join(fs.WORKING_DIR_PP,fs.PST_NAME_PP))\n",
    "inpst.control_data.noptmax =  -1\n",
    "inpst.write(os.path.join(fs.WORKING_DIR_PP,'freyberg_pp_jac.pst'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if runall_flag is True:\n",
    "    os.chdir(fs.WORKING_DIR_PP)\n",
    "    pyemu.helpers.start_slaves('.', 'pestpp', 'freyberg_pp_jac.pst', num_slaves=15,master_dir='.')\n",
    "    os.chdir('..')\n",
    "else:\n",
    "    if not os.path.exists(fs.WORKING_DIR_PP):\n",
    "        os.mkdir(fs.WORKING_DIR_PP)\n",
    "    shutil.copy2('freyberg_pp_jac.jcb',os.path.join(fs.WORKING_DIR_PP, 'freyberg_pp_jac.jcb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at the Jacobian matrix---gradients of parameters wrt. observations\n",
    "\n",
    "For each parameter-observation combination, we can see how much the observation value changes due to a small change in the parameter. If $y$ are the observations and $x$ are the parameters, the equation for the $i^th$ observation with respect to the $j^th$ parameter is:  \n",
    "## $\\frac{\\partial y_i}{\\partial x_j}$\n",
    "This can be approximated by finite differences as :  \n",
    "## $\\frac{\\partial y_i}{\\partial x_j}~\\frac{y\\left(x+\\Delta x \\right)-y\\left(x\\right)}{\\Delta x}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First we can read in a couple Jacobian matrices -- one from our simple model, and one from a more complex one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "jac_simple = pyemu.Jco.from_binary(os.path.join(working_dir,'freyberg_kr.final.jcb'))\n",
    "jac_complex = pyemu.Jco.from_binary(os.path.join(fs.WORKING_DIR_PP, 'freyberg_pp_jac.jcb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### These are now matrices. How big are they?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('simple  --> {0} rows x {1} columns'.format(*jac_simple.shape))\n",
    "print ('complex --> {0} rows x {1} columns'.format(*jac_complex.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's drop all the forecasts and regularization information\n",
    "jac_simple.drop([x for x in jac_simple.df().index if x.startswith('pr')], axis=0)\n",
    "jac_simple.drop([x for x in jac_simple.df().index if x.startswith('fr')], axis=0)\n",
    "jac_simple.drop('travel_time', axis=0)\n",
    "\n",
    "jac_complex.drop([x for x in jac_complex.df().index if x.startswith('pr')], axis=0)\n",
    "jac_complex.drop([x for x in jac_complex.df().index if x.startswith('fr')], axis=0)\n",
    "jac_complex.drop('travel_time', axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jac_simple.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sih.plot_Jacobian(jac_simple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## how about just the first 20 observations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sih.plot_Jacobian(jac_simple[:20,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sih.plot_Jacobian(jac_complex[:20,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Can be more informative to look at sensitivity spatially"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(jac_complex.row_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sih.plot_jacobian_spatial(jac_complex,'cr34c08_19700102');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with PdfPages('allsens.pdf') as ofp:\n",
    "    for cob in jac_complex.row_names:\n",
    "        if 'flx' not in cob and 'vol' not in cob:\n",
    "            cf = sih.plot_jacobian_spatial(jac_complex, cob)\n",
    "            ofp.savefig()\n",
    "            plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How about Composite Scaled Sensitivities\n",
    "In the traditional, overdetermined regression world, CSS was a popular metric. CSS is Composite Scaled Sensitivitity.\n",
    "\n",
    "In Hill and Tiedeman (2007) this is calculated as: \n",
    "## ${css_{j}=\\sqrt{\\left(\\sum_{i-1}^{ND}\\left(\\frac{\\partial y'_{i}}{\\partial b_{j}}\\right)\\left|b_{j}\\right|\\sqrt{w_{ii}}\\right)/ND}}$\n",
    "\n",
    "In PEST, Doherty calculates it slightly differently in that scaling by the parameter values happens automatically when the parameter is subjected to a log-transform. This is due to a correction that must be made in calculating the Jacobian matrix and follows from the chain rule of derivatives.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "la = pyemu.LinearAnalysis(jco=os.path.join(os.path.join(fs.WORKING_DIR_PP, 'freyberg_pp_jac.jcb')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "ax = la.get_par_css_dataframe()['pest_css'].sort_values(ascending=False).plot(kind='bar')\n",
    "ax.set_yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's consider correlation and posterior covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = pyemu.Schur(os.path.join(os.path.join(fs.WORKING_DIR_PP, 'freyberg_pp_jac.jcb')))\n",
    "covar = pyemu.Cov(sc.xtqx.x, names=sc.xtqx.row_names)\n",
    "covar.df().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = covar.to_pearson()\n",
    "plt.imshow(R.df(), interpolation='nearest', cmap='viridis')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpar = 'hk10'\n",
    "R.df().loc[cpar][np.abs(R.df().loc[cpar])>.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_plot = R.df().as_matrix()\n",
    "R_plot[np.abs(R_plot)>.9] = np.nan\n",
    "plt.imshow(R_plot, interpolation='nearest', cmap='viridis')\n",
    "plt.colorbar()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
