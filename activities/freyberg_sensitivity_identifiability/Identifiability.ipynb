{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"PEST++V3_cover.jpeg\" style=\"float: left\">\n",
    "\n",
    "<img src=\"flopylogo.png\" style=\"float: right\">\n",
    "\n",
    "<img src=\"AW&H2015.png\" style=\"float: center\">\n",
    "\n",
    "# Looking at Parameter Identifiability\n",
    "\n",
    "Sensitivity analyses can mask other artifacts that affect calibration and uncertainty. A primary issues is correlation between parameters.  For example, we saw that in a heads-only calibration we can't estimate both recharge and hydraulic conductivity independently - the parameters are correlated so that an increase in one can be offset with an increase in the other.  To address this shortcoming, Doherty and Hunt (2009) show that singular value decomposition can extend the sensitivity insight into __*parameter identifiability*__.  Parameter identifiability combines parameter insensitivity and correlation information, and reflects the robustness with which particular parameter values in a model might be calibrated. That is, an identifiable parameter is both sensitive and relatively uncorrelated and thus is more likely to be estimated (identified) than an insensitive and/or correlated parameter. \n",
    "\n",
    "Parameter identifiability is considered a \"linear method\" in that it assumes the Jacobian matrix sensitivities hold over a range of reasonable parameter values.  It is able to address parameter correlation through singular value decomposition (SVD), exactly as we've seen earlier in this course.  Parameter identifiability ranges from 0 (perfectly unidentifiable with the observations available) to 1.0 (fully identifiable). So, we typically plot identifiability using a stacked bar chart which is comprised of the included singular value contributions. Another way to think of it: if a parameter is strongly in the SVD solution space (low singular value so above the cutoff) it will have a higher identifiability. However, as Doherty and Hunt (2009) point out, identifiability is qualitative in nature because the singular value cutoff is user specified. \n",
    "\n",
    "You can access parameter identifiability at the command line using the PEST utility __*identpar*__.  As always, when you type identpar without arguments you'll get what the utility needs to run. For identpar.exe it looks like:\n",
    "\n",
    "\n",
    "\n",
    "    IDENTPAR Version 14.01. Watermark Numerical Computing.\n",
    "\n",
    "\n",
    "    IDENTPAR is run using the command:\n",
    "\n",
    "        IDENTPAR casename numvec outbase matfile identfile [/s or /r]\n",
    "\n",
    "    where\n",
    "\n",
    "        casename  is a PEST control file basename,\n",
    "        numvec    is the number of singular values to use,\n",
    "        outbase   is the filename base of sensitivity vector output files,\n",
    "        outfile   is the name of a matrix output file\n",
    "        identfile is the name of a parameter identifiability output file, and\n",
    "        /s or /r  instigates SVD on XtQX or Q^(1/2)X respectively (/s is default).\n",
    "\n",
    "        Note: enter a filename of \"null\" for no pertinent output file.\n",
    "\n",
    "\n",
    "The input of __numvec__ specifies the singular value cutoff that is used to calculate identifiability; the __identfile__ above provides the output in a format suitable for plotting.  \n",
    "\n",
    "However, in our example here __we won't use the command line PEST utility__ but will instead take advantage of the pyemu version of parameter identifiability for convenience. Let's take a look at it more closely and see what we can learn from it and how to handle such information as the number of parameters rises.\n",
    "\n",
    "### One last cool concept about identifiability the Doherty and Hunt (2009) point out:  \n",
    "Because parameter identifiability uses the Jacobian matrix it is the *sensitivity* that matters, not the actual value specified. This means you can enter *hypothetical observations* to the existing observations, re-run the Jacobian matrix, and then re-plot identifiability. In this way identifiability becomes a quick but qualitative way to look at the worth of future data collection - an underused aspect of our modeling!   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyemu\n",
    "import os, shutil\n",
    "import re\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "runall= False\n",
    "import sensitivity_identifiability_helper as sih"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import freyberg_setup as fs\n",
    "fs.setup_pest_pp()\n",
    "working_dir = fs.WORKING_DIR_PP\n",
    "pst_name = fs.PST_NAME_PP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs.plot_model(working_dir, pst_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We need to calculate a Jacobian Matrix to look at sensitivity and identifiability\n",
    "\n",
    "## we just need to sen `NOPTMAX=-1` in the PST control file and run PESTPP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inpst = pyemu.Pst(os.path.join(working_dir,'freyberg_pp.pst'))\n",
    "inpst.control_data.noptmax=-1\n",
    "inpst.write(os.path.join(working_dir,'freyberg_jac.pst'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if runall==True:\n",
    "    os.chdir(working_dir)\n",
    "    pyemu.helpers.run('pestpp freyberg_jac.pst')\n",
    "    os.chdir('..')\n",
    "else:\n",
    "    shutil.copy2('freyberg_jac.jcb', os.path.join(working_dir,'freyberg_jac.jcb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's load up the resulting Jacobian and look at sensitivity and identifiability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a Schur Complement object in `pyemu`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = pyemu.Schur(jco=os.path.join(working_dir,'freyberg_jac.jcb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## among other things, this loads the Jacobian matrix (called `jco`) as a property"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(sc.jco.x[:25,:25].T)\n",
    "plt.colorbar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.log10(np.abs(sc.jco.x[:25,:25].T)))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svals = sc.xtqx.s\n",
    "plt.plot(svals.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(svals.x)\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To look at identifiability we will need to create an `ErrVar` object in `pyemu`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ev = pyemu.ErrVar(jco=os.path.join(working_dir,'freyberg_jac.jcb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We can get a dataframe of identifiability for any singular value cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_df = ev.get_identifiability_dataframe(singular_value=5).sort_values(by='ident', ascending=False)\n",
    "id_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## It's easy to visualize these as stacked bar charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = sih.plot_id_bars(ev, 150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More meaningful to look at a singular value cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = sih.plot_id_bars(ev,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How does this compare with CSS (Composite Scaled Sensitivities)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,4))\n",
    "ax = sc.get_par_css_dataframe()['pest_css'].sort_values(ascending=False).plot(kind='bar')\n",
    "ax.set_yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We can read in the MLE covariance and look at correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covar = pyemu.Cov(sc.xtqx.x, names=sc.xtqx.row_names)\n",
    "covar.df().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = covar.to_pearson()\n",
    "plt.imshow(R.df(), interpolation='nearest', cmap='viridis')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's look at correlation\n",
    "CSS suffers from the challenge that values with high CSS may be corelated with other parameters. We can check that out. Identifiability, on the other hand, tends to spread among the correlated parameters so that identifiability is suppressed from each of those parameters. This makes a big difference between what is \"sensitive\" vs. \"identifiable\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpar = 'w0_r09_c16'\n",
    "R.df().loc[cpar][np.abs(R.df().loc[cpar])>.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sih.plot_identifiability_spatial(ev, 13, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
