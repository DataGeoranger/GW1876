{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"PEST++V3_cover.jpeg\" style=\"float: left\">\n",
    "\n",
    "<img src=\"flopylogo.png\" style=\"float: right\">\n",
    "\n",
    "<img src=\"AW&H2015.png\" style=\"float: center\">\n",
    "\n",
    "# SINGULAR VALUE DECOMPOSITION (SVD)\n",
    "\n",
    ">## \"A singularly valuable decomposition\" \n",
    ">--Dan Kalman \n",
    "\n",
    ">## \"Singular Value Decomposition. Love it, learn it.\"\n",
    ">--Michael Basial\n",
    "\n",
    ">## \"SVD? Magic, simply magic.\"\n",
    ">--John Doherty\n",
    "\n",
    "### As we've said, the key to representative environmental models is allowing high levels of flexibility through a highly parameterized approach.  But this makes our parameter estimation problem illposed and underdetermined, which means our solution is nonunique even if we overcome problems of increased instability and longer runtimes.  Here we use a \"regularized inversion\" approach to overcome these problems.  Regularization is anything that makes an intractable problem solvable; for example, using a small number of zones (not highly-parameterized) is a way to regularize an illposed problem.  Regularization as we use here can be grouped into two broad categories: 1) adding soft-knowledge to the problem (Tikhonov regularization) and 2) mathematically reducing the dimensionality of the model (subspace regularization via singular value decomposition (SVD)). In practice we typically use a combination (\"hybrid\") of these two approaches. \n",
    "\n",
    "### It is worth expounding on this difference in regularization approaches. In contrast to Tikhonov regularization, which adds information to the calibration process to achieve numerical stability, subspace methods achieve stability through subtracting parameters, and/or parameter combinations, from the calibration process (making a \"subspace\" of the full parameter space). Now the calibration process is no longer required to estimate either individual parameters or combinations of correlated parameters that are inestimable given the calibration dataset we have. What combinations are estimable are automatically determined through SVD. \n",
    "\n",
    "### The effort needed to take advantage of these regularization strategies is also appreciably different, where SVD is relatively easily brought to bear and becomes \"set it and forget it\". Moreover, when SVD is used the parameter estimation problem always becomes __unconditionally stable__! Neither of these is true in all cases when adding soft knowledge using Tikhonov regularization. \n",
    "\n",
    "### In summary, SVD benefits apply to all models so it is worth widely invoking when using PEST and PEST++.  SVD involves few parameter estimation inputs, default values work for a large range of problems, and it addresses instability for all problems. Can you catch that we can't overemphasize the importance of SVD to parameter estimation?  \"Magic\" indeed! \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this and the next notebooks we'll get under the hood of SVD and see what it does.  A high-level understanding is not needed to take advantage of the power of SVD for your typical calibration parameter estimation problem (\"set it and forget it\").  BUT in addition to the glow of knowledge that they impart, these SVD concepts will cascade into understanding other tools such as Parameter Identifiability, calculation of uncertainty, and null-space Monte Carlo.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "import flopy as fp\n",
    "import numpy as np\n",
    "import pyemu\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.pyplot import cm \n",
    "\n",
    "    \n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Algebra is the foundation of much of our maths and modeling. At the basis of this is matrices, which are containing vector information like spatial array of properties, mappings from one set of properties to another, the variability of properties."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another example of a matrix is just a photograph. It turns out, much of the information contained in a matrix is redundant. If we think of the columns of a matrix as vectors, they are orthogonal but maybe aren't quite the right basis for the infromation. What if we could find another basis, where we rotate to a more suitable set of orthogonal basis vectors and maybe even stretch them?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Any matrix can be decomposed into 3 matrices\n",
    "## <center> $\\mathbf{M}=\\mathbf{U}\\mathbf{S}\\mathbf{V}^T$ </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "import flopy as flopy\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "noPIL=True\n",
    "try:\n",
    "    from PIL import Image\n",
    "except:\n",
    "    noPIL=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's evaluate how this works by exploring the information content in an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "photo = Image.open('clands.jpg')\n",
    "\n",
    "plt.imshow(photo, interpolation='nearest')\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to grayscale\n",
    "\n",
    "### By converting to grayscale, what we are left with is a matrix of information where each pixel (e.g. a cell in rows/columns of the matrix) has a value between 0 and 255 indicating intensity. This is then just a matrix with information in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not noPIL:\n",
    "    photogray = np.array(photo.convert('L'))\n",
    "    np.savetxt('clands_gray.dat', photogray, fmt='%d')\n",
    "else:\n",
    "    photogray = np.loadtxt('clands_gray.dat', dtype=int)\n",
    "plt.imshow(photogray, interpolation='nearest', cmap='gray')\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We can treat this like any matrix and perform SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U, sigma, V = np.linalg.svd(photogray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(sigma)\n",
    "plt.grid()\n",
    "plt.title('{0} Singular values in descending order'.format(len(sigma)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(sigma)\n",
    "plt.grid()\n",
    "plt.title('{0} Singular values in descending order'.format(len(sigma)));\n",
    "plt.yscale('log');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's make a little function for using a subset of singular values to reconstitute the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recon_image(U,sigma,V,numsing=1, photo=None, printflag=False):\n",
    "    reconimg = np.dot(np.dot(U[:,:numsing], np.diag(sigma[:numsing])),V[:numsing,:])\n",
    "    basis_vec = np.dot(np.dot(np.atleast_2d(U[:,numsing-1]).T, sigma[numsing-1]),np.atleast_2d(V[numsing-1,:]))\n",
    "    fig,ax = plt.subplots(ncols=2, figsize=(8,8))\n",
    "    ax[0].imshow(basis_vec, interpolation='nearest', cmap='gray')\n",
    "    ax[0].axis('off')\n",
    "    ax[0].set_title('Basis Image')\n",
    "    ax[1].imshow(reconimg, interpolation='nearest', cmap='gray')\n",
    "    ax[1].axis('off')\n",
    "    ss = 's'\n",
    "    if numsing==1:\n",
    "        ss = ''\n",
    "    ax[1].set_title('Reconstruction using {0} singular value{1}'.format(numsing,ss))\n",
    "    plt.tight_layout()\n",
    "    if printflag==True:\n",
    "        plt.savefig(os.path.join('pngs','svd_{0}.png'.format(numsing)), bbox_inches='tight', pad_inches=0.2)\n",
    "        plt.close()\n",
    "    return basis_vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec=recon_image(U,sigma,V,1)\n",
    "#plt.imshow(rec,cmap='gray')\n",
    "#plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We can also make images sequentially adding singular values\n",
    "\n",
    "Note - this requires `ffmpeg` to be installed\n",
    "\n",
    "Also note the two flags set to `False` for now to be sure that we only remake them if we want to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import platform\n",
    "if 'window' in platform.platform().lower():\n",
    "    pref = ''\n",
    "else:\n",
    "    pref = './'\n",
    "make_images=False\n",
    "make_movie=False\n",
    "\n",
    "if make_images:\n",
    "    if not os.path.exists('pngs'):\n",
    "        os.mkdir('pngs')\n",
    "    for i in range(len(sigma)):\n",
    "        print(i)\n",
    "        recon_image(U, sigma, V, i+1,photogray, True)\n",
    "\n",
    "if make_movie:\n",
    "    if os.path.exists('svdmovie.mp4'):\n",
    "        os.remove('svdmovie.mp4')\n",
    "    runstr='{0}ffmpeg -f image2 -r 10  -i pngs/svd_%d.png -vcodec libx264 -pix_fmt yuv420p -vf \"scale=trunc(iw/2)*2:trunc(ih/2)*2\" svdmovie.mp4'.format(pref)\n",
    "    os.system(runstr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fun times, but what does this have to do with modeling?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyemu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's load up a Jacobian Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "injac = pyemu.Jco.from_binary('freyberg_pp.jcb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "injac.df().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inpst = pyemu.Pst('freyberg_pp.pst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = inpst.observation_data.weight.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = np.diag(Q)\n",
    "Q.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = injac.df().as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.log(np.abs(X)), interpolation='nearest', cmap='viridis')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.log(np.abs(X[:50,:50])), interpolation='nearest', cmap='viridis')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We can form up the normal equations matrix (including weights) and take a look at it\n",
    "\n",
    "This matrix is $\\mathbf{X}^T\\mathbf{Q}\\mathbf{X}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XtQX=X.T.dot(Q).dot(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U, sigma, V = np.linalg.svd(XtQX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(range(len(sigma)),sigma)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(range(len(sigma)),sigma)\n",
    "plt.yscale('log')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.log(XtQX), interpolation='nearest', cmap='viridis')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(V[:13,:13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select which singular vector you want to plot\n",
    "SV=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SV_bars(SV=1):\n",
    "    plt.figure(figsize=(13,4))\n",
    "    plt.bar(list(range(U.shape[0])),U[:,SV-1])\n",
    "    #plt.yscale('log')\n",
    "    plt.xlim([0,55])\n",
    "    plt.xticks(list(range(55)))\n",
    "    plt.title('Singular vector showing parameter contributions to singular vector #{0}'.format(SV))\n",
    "    plt.gca().set_xticklabels(inpst.parameter_data['parnme'], rotation=90);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact(SV_bars, SV=widgets.widgets.IntSlider(\n",
    "    value=1, min=1, max=20, step=1, description='Number SVs:',\n",
    "    disabled=False, continuous_update=True, orientation='horizontal', readout=True, readout_format='d'));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Great - finally how does this impact our calibration of a K-field?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import freyberg_setup as fs\n",
    "fs.setup_pest_gr()\n",
    "working_dir = fs.WORKING_DIR_GR\n",
    "pst_name = fs.PST_NAME_GR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = flopy.modflow.Modflow.load(fs.MODEL_NAM,model_ws=working_dir,load_only=[\"upw\"],check=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = pyemu.geostats.ExpVario(1.0,a=200,anisotropy=1.0,bearing=45)\n",
    "struct = pyemu.geostats.GeoStruct(variograms=v)\n",
    "arr_dict = {\"test\":np.ones((m.nrow,m.ncol))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd = pyemu.helpers.kl_setup(num_eig=800,sr=m.sr,struct=struct,array_dict=arr_dict,basis_file=\"basis.jco\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basis = pyemu.Matrix.from_binary(\"basis.jco\").to_dataframe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = basis.index.map(lambda x: int(x[1:5]))\n",
    "j = basis.index.map(lambda x: int(x[-4:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's check out the zoned K field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.loadtxt(os.path.join(\"..\",\"..\",\"models\",\"Freyberg\",\"Freyberg_Truth\",\"hk.zones\"))\n",
    "plt.figure(figsize=(4,8))\n",
    "mm = flopy.plot.ModelMap(model=m, ax=plt.gca())\n",
    "mm.plot_array(arr)\n",
    "mm.plot_ibound();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_eig_arr(eig):\n",
    "    plt.figure(figsize=(4,8))\n",
    "    arr = np.zeros((m.nrow,m.ncol))\n",
    "    arr[i,j] = basis.iloc[:,eig]\n",
    "    mm = flopy.plot.ModelMap(model=m, ax=plt.gca())\n",
    "    mm.plot_array(arr)\n",
    "    mm.plot_ibound()\n",
    "    #mm = plt.imshow(arr)\n",
    "    plt.title('Plot of SV# {0}'.format(eig))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact(plot_eig_arr, eig=widgets.IntSlider(description=\"eig comp:\", \n",
    "                                           continuous_update=True, max=799));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We can also reconstruct the K field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basis_arr = np.array(basis.values)\n",
    "flat_arr = np.atleast_2d(arr.flatten()).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_enchilada(eig):\n",
    "    fig,ax = plt.subplots(ncols=2, figsize=(8,8))\n",
    "    arr = np.zeros((m.nrow,m.ncol))\n",
    "    arr[i,j] = basis.iloc[:,eig]\n",
    "    mm = flopy.plot.ModelMap(model=m, ax=ax[0])\n",
    "    mm.plot_array(arr)\n",
    "    mm.plot_ibound()\n",
    "    #mm = plt.imshow(arr)\n",
    "    ax[0].set_title('Plot of individual CV')\n",
    "    basis_eig = basis_arr[:,:eig+1].transpose()\n",
    "    factors = np.dot(basis_eig,flat_arr).transpose()\n",
    "    factors = np.dot(factors,basis_eig).reshape(arr.shape)\n",
    "    mm2 = flopy.plot.ModelMap(model=m, ax=ax[1])\n",
    "    mm2.plot_array(factors)\n",
    "    mm2.plot_ibound()\n",
    "    ax[1].set_title('Reconstructed field')\n",
    "    plt.suptitle('Using {0} SVs'.format(eig+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact(plot_enchilada, eig=widgets.IntSlider(description=\"eig comp:\", \n",
    "                                           continuous_update=True, max=799));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
