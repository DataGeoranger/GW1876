{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import print_function\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib.patches import Rectangle as rect\n",
    "import matplotlib.pyplot as plt\n",
    "import platform\n",
    "if 'window' in platform.platform().lower():\n",
    "    pref = ''\n",
    "else:\n",
    "    pref = './'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Null-Space Monte Carlo with Freyberg Model\n",
    "\n",
    "Adapted from the examples provided with `pyemu`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using `pyemu`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pyemu\n",
    "import shutil, os\n",
    "\n",
    "basedir = os.path.join('..','..','models','Freyberg','Freyberg_pilotpoints')\n",
    "[shutil.copy2(os.path.join(basedir,cf),cf) for cf in os.listdir(basedir)];\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First create a linear analysis object.  We will use `MonteCarlo`  derived type, which allows us to use some sampling based methods.  We pass it the name of the jacobian matrix file.  Since we don't pass an explicit argument for `parcov` or `obscov`, `pyemu` attempts to build them from the parameter bounds and observation weights in a pest control file (.pst) with the same base case name as the jacobian.  Since we are interested in forecast uncertainty as well as parameter uncertainty, we also pass the names of the forecast sensitivity vectors we are interested in, which are stored in the jacobian as well.  Note that the `forecasts` argument can be a mixed list of observation names, other jacobian files or PEST-compatible ASCII matrix files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get the list of forecast names from the pest++ argument in the pest control file\n",
    "jco_file = 'freyberg_pp.jcb'\n",
    "pst_file = 'freyberg_pp.pst'\n",
    "pst = pyemu.Pst(pst_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mc = pyemu.MonteCarlo(jco=jco_file, forecasts=pst.pestpp_options[\"forecasts\"].split(','),verbose=False)\n",
    "print(\"observations,parameters in jacobian:\",mc.jco.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mc.jco.df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pst.pestpp_options[\"forecasts\"].split(',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drawing from the prior\n",
    "Each ``MonteCarlo`` instance has a ``parensemble`` attribute which itself is an instance of ``Ensemble`` class, which is derived from ``pandas.DataFrame``.  What all that means is that the parameter ensembles behave just like ```DataFrame```s\n",
    "\n",
    "### ```draw```\n",
    "The ``draw`` method is the main entry point into getting realizations. It accepts several optional arguments.  Without any args, it makes a single draw from the prior, which uses a $\\boldsymbol{\\mu}$ (mean) vector of the parameter values listed in the pest control file:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mc.draw()\n",
    "print(mc.parensemble.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``draw`` also accepts a ``num_reals`` argument to specify the number of draws to make:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mc.draw(num_reals=200)\n",
    "print(mc.parensemble.shape)\n",
    "print(mc.parensemble.mean().head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that each call to ``draw`` overwrites the previous draws.  ```draw``` also accepts a ``par_file`` argument in the case that you want to use a pest .par file as the $\\boldsymbol{\\mu}$ vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mc.draw(num_reals=200)\n",
    "print(mc.parensemble.mean().head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Notice how the mean value for ``rond00`` is different.  ``draw`` also accepts an ``obs`` boolean flag to control include drawing a realization of observation noise.  If ```obs``` is True, then a complimentary ```obsensemble``` attribute is also populated.  The last optional flag for ```draw``` is ``enforce_bounds``, which controls whether parameter bounds are explicitly respected:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```.draw``` also accepts an optional ``how`` argument that controls the type of distribution to draw from.  ``how`` can be either \"gaussian\" (default) or \"uniform\".  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plotting\n",
    "\n",
    "Since ```ParameterEnsemble``` is dervied from ```pandas.DataFrame```, it has all the cool methods and attributes we all love.  Let's compare the results of drawing from a uniform vs a gaussian distribution.  This may take some time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mc.parensemble.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mc.draw(num_reals=500,how=\"uniform\")\n",
    "ax = plt.subplot(111)\n",
    "partoplot = 'hkpp10'\n",
    "mc.parensemble.loc[:,partoplot].plot(kind=\"hist\",bins=50,ax=ax,alpha=0.5, normed=True)\n",
    "mc.draw(num_reals=500,how=\"gaussian\")\n",
    "mc.parensemble.loc[:,partoplot].plot(kind=\"hist\",bins=50,ax=ax,alpha=0.5, normed=True)\n",
    "plt.legend(['uniform','gaussian'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## null-space projection \n",
    "\n",
    "This is too easy.  Once you have drawn parameter realization, use the ```project_parensemble()``` method.  This method accepts 3 optional arguemnts: ``nsing``: number of singular components to demarcate the solution-null space boundary, ``par_file``: a pest .par file to use as the final parameter values, and ``inplace``, which is a boolean flag to control whether a new ```Ensemble``` instance should be created and returned.  The most important of these is ``nsing``.  If it is not passed, then ``nsing`` is set based on the ratio between the largest and smallest singular values >= 1.0e-6 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mc.draw(num_reals=1000,enforce_bounds=True)\n",
    "unprojected50 = mc.parensemble.copy()\n",
    "mc.project_parensemble(nsing=50,par_file=\"freyberg_pp.par\") #use nsing=50 for demonstration purposes\n",
    "projected50 = mc.parensemble.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "partoplot = 'hkpp10'\n",
    "ax = plt.subplot(111)\n",
    "unprojected50.loc[:,partoplot].plot(kind=\"hist\",bins=50,ax=ax,alpha=0.5)\n",
    "projected50.loc[:,partoplot].plot(kind=\"hist\",bins=50,ax=ax,alpha=0.5)\n",
    "plt.legend(['unprojected','projected'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that if we use a large number of singular components, then the null-space projection process greatly reduces the uncertainty in the ``rch_1`` parameter.  Note that using 50 singular components greatly overeastimates the dimension of the range space of the normal matrix ($\\mathbf{J}^T\\mathbf{Q}\\mathbf{J}$) and is likely not justifiable, since only 12 observations are being used for inversion. Let's redo the redo the null-space projection operation with 12 singular components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mc.draw(num_reals=1000,enforce_bounds=True)\n",
    "unprojected12 = mc.parensemble.copy()\n",
    "mc.project_parensemble(nsing=12,par_file=\"freyberg_pp.par\") #use nsing=50 for demonstration purposes\n",
    "projected12 = mc.parensemble.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "partoplot = 'hkpp10'\n",
    "ax = plt.subplot(111)\n",
    "unprojected12.loc[:,partoplot].plot(kind=\"hist\",bins=50,ax=ax,alpha=0.5, normed=True)\n",
    "projected12.loc[:,partoplot].plot(kind=\"hist\",bins=50,ax=ax,alpha=0.5, normed=True)\n",
    "plt.legend(['unprojected','projected'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we see that the null-space projection operation only slightly increases the kurtosis of the distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How does this all pan out when we run the models?\n",
    "\n",
    "Let's look at three options:  \n",
    "1. unconstrained Monte Carlo (like we did before with just K and R)  \n",
    "2. posterior sampling Null Space Monte Carlo \n",
    "3. posterior sampling Null Space Monte Carlo with a single iteration using existing Jacobian\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### first, unconstrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mc = pyemu.MonteCarlo(jco=jco_file, forecasts=pst.pestpp_options[\"forecasts\"].split(','),verbose=False)\n",
    "mc.draw(num_reals=1000, enforce_bounds=True,how='gaussian')\n",
    "mc.parensemble.to_csv('sweep_in.csv')\n",
    "shutil.copy('sweep_in.csv','unconstrained_pars.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# now run using sweep\n",
    "if not os.path.exists('unconbase'):\n",
    "    os.mkdir('unconbase')\n",
    "[shutil.copy2(cf,os.path.join('unconbase',cf)) \n",
    " for cf in os.listdir(os.getcwd()) if not os.path.isdir(cf)];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pyemu.helpers.start_slaves('unconbase',\"{0}sweep\".format(pref),\"freyberg_pp.pst\",num_slaves=20,master_dir='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# copy over the results\n",
    "shutil.copy('sweep_out.csv','unconstrained_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "uncon_results = pd.read_csv('unconstrained_results.csv')\n",
    "uncon_results.phi.hist(bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### now with the constrained samples (from the posterior) with 50 singular values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mc = pyemu.MonteCarlo(jco=jco_file, forecasts=pst.pestpp_options[\"forecasts\"].split(','),verbose=False)\n",
    "mc.draw(num_reals=1000, enforce_bounds=True,how='gaussian')\n",
    "mc.project_parensemble(nsing=50,par_file=\"freyberg_pp.par\") #use nsing=50 for demonstration purposes\n",
    "mc.parensemble.to_csv('sweep_in.csv')\n",
    "shutil.copy('sweep_in.csv','constrained_50sv_pars.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# now run using sweep\n",
    "if not os.path.exists('conbase50'):\n",
    "    os.mkdir('conbase50')\n",
    "[shutil.copy2(cf,os.path.join('conbase50',cf)) \n",
    " for cf in os.listdir(os.getcwd()) if not os.path.isdir(cf)];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pyemu.helpers.start_slaves('conbase50',\"{0}sweep\".format(pref),\"freyberg_pp.pst\",num_slaves=20,master_dir='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# copy over the results\n",
    "shutil.copy('sweep_out.csv','constrained_50_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "con50_results = pd.read_csv('constrained_50_results.csv')\n",
    "ax = con50_results.phi.hist(bins=50, alpha=.5, normed=True)\n",
    "uncon_results.phi.hist(bins=50, alpha=.5, ax=ax, normed=True)\n",
    "plt.legend(['con50','uncon'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### now with the constrained samples (from the posterior) with 12 singular values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mc = pyemu.MonteCarlo(jco=jco_file, forecasts=pst.pestpp_options[\"forecasts\"].split(','),verbose=False)\n",
    "mc.draw(num_reals=1000, enforce_bounds=True,how='gaussian')\n",
    "mc.project_parensemble(nsing=12,par_file=\"freyberg_pp.par\") #use nsing=50 for demonstration purposes\n",
    "mc.parensemble.to_csv('sweep_in.csv')\n",
    "shutil.copy('sweep_in.csv','constrained_12sv_pars.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# now run using sweep\n",
    "if not os.path.exists('conbase12'):\n",
    "    os.mkdir('conbase12')\n",
    "[shutil.copy2(cf,os.path.join('conbase12',cf)) \n",
    " for cf in os.listdir(os.getcwd()) if not os.path.isdir(cf)];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pyemu.helpers.start_slaves('conbase12',\"{0}sweep\".format(pref),\"freyberg_pp.pst\",num_slaves=20,master_dir='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# copy over the results\n",
    "shutil.copy('sweep_out.csv','constrained_12_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "con12_results = pd.read_csv('constrained_12_results.csv')\n",
    "ax = con12_results.phi.hist(bins=50, alpha=.5)\n",
    "uncon_results.phi.hist(bins=50, alpha=.5, ax=ax)\n",
    "plt.legend(['con12','uncon'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Now let's subject this last parameter set to a single linearization using the existing Jacobian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('conbase12relin'):\n",
    "    os.mkdir('conbase12relin')\n",
    "[shutil.copy2(cf,os.path.join('conbase12relin',cf)) \n",
    " for cf in os.listdir(os.getcwd()) if not os.path.isdir(cf)];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mc.write_psts(os.path.join('conbase12relin','freyberg_pp_12relin_real'),\n",
    "              existing_jco=\"freyberg_pp.jcb\",noptmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# make a simple script to run all of these\n",
    "with open(os.path.join('conbase12relin','runall.py'), 'w') as ofp:\n",
    "    ofp.write('import os \\n')\n",
    "    ofp.write('for cf in os.listdir(os.getcwd()): \\n')\n",
    "    ofp.write(\"    if cf.endswith('.pst') and 'real' in cf: \\n\")\n",
    "    if 'window' in platform.platform().lower():\n",
    "        ofp.write(\"        os.system('pest++ {0} '.format(cf))\")\n",
    "    else:\n",
    "        ofp.write(\"        os.system('pest++ {0} '.format(cf))\")\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Now we can read in all the PHI values from the `iobj` files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.path.join('conbase12relin', 'freyberg_pp_12relin_real{0}.iobj'.format(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tmp = pyemu.Pst(os.path.join('conbase12relin', 'freyberg_pp_12relin_real{0}.pst'.format(0)))\n",
    "con12relin_forecasts = pd.DataFrame.from_records(\n",
    "    dict(zip([i.upper() for i in tmp.res.name.values],tmp.res.modelled.values)), index=[0])\n",
    "\n",
    "con12relin_results = pd.read_csv(os.path.join('conbase12relin', 'freyberg_pp_12relin_real{0}.iobj'.format(0)))  \n",
    "\n",
    "for creal in range(1, 1000):\n",
    "    try:\n",
    "        con12relin_results=con12relin_results.append(pd.read_csv(\n",
    "                os.path.join('conbase12relin', 'freyberg_pp_12relin_real{0}.iobj'.format(creal))))  \n",
    "        tmp = pyemu.Pst(os.path.join('conbase12relin', 'freyberg_pp_12relin_real{0}.pst'.format(creal)))\n",
    "\n",
    "        con12relin_forecasts=con12relin_forecasts.append(pd.DataFrame.from_records(\n",
    "    dict(zip([i.upper() for i in tmp.res.name.values],tmp.res.modelled.values)), index=[0]))\n",
    "    except:\n",
    "        print('No dice on realization {0}'.format(creal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ax=con12relin_results.loc[con12relin_results.iteration==0].total_phi.hist(bins=50, alpha=0.5)\n",
    "con12relin_results.loc[con12relin_results.iteration==1].total_phi.hist(bins=50, alpha=0.5,ax=ax)\n",
    "plt.legend(['nonlinearized','linearized'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "con12_results.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We can see what this all does to PHI, but what about our forecasts?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pltpar='FR30C16'\n",
    "ax=con12_results.loc[con12_results[pltpar]>0][pltpar].hist(bins=50, alpha=.5)\n",
    "con50_results.loc[con50_results[pltpar]>0][pltpar].hist(bins=50, alpha=.5, ax=ax)\n",
    "plt.legend(['con12','con50'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pltpar='FR04C9'\n",
    "ax=con12_results.loc[con12_results[pltpar]>0][pltpar].hist(bins=50, alpha=.5)\n",
    "con50_results.loc[con50_results[pltpar]>0][pltpar].hist(bins=50, alpha=.5, ax=ax)\n",
    "plt.legend(['con12','con50'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pltpar='RIVFLUX_FORE'\n",
    "ax=con12_results.loc[con12_results[pltpar]>-1e8][pltpar].hist(bins=50, alpha=.5)\n",
    "con50_results.loc[con50_results[pltpar]>-1e8][pltpar].hist(bins=50, alpha=.5, ax=ax)\n",
    "plt.legend(['con12','con50'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pltpar='RIVFLUX_FORE'\n",
    "ax=con12_results.loc[con12_results[pltpar]>-1e8][pltpar].hist(bins=50, alpha=.5)\n",
    "con12relin_forecasts.loc[con12relin_forecasts[pltpar]>-1e8][pltpar].hist(bins=50, alpha=.5, ax=ax)\n",
    "plt.legend(['con12','con50'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pltpar='TRAVEL_TIME'\n",
    "ax=con12_results.loc[con12_results[pltpar]>-1e8][pltpar].hist(bins=50, alpha=.5, normed=True)\n",
    "con12relin_forecasts.loc[con12relin_forecasts[pltpar]>-1e8][pltpar].hist(bins=50, alpha=.5, ax=ax,normed=True)\n",
    "plt.legend(['con12','con50'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "con12relin_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
