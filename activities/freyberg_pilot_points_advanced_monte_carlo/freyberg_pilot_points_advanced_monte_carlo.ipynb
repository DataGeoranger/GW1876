{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import print_function\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib.patches import Rectangle as rect\n",
    "import matplotlib.pyplot as plt\n",
    "import pyemu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import freyberg_setup as fs\n",
    "fs.setup_pest_pp()\n",
    "pst_name = fs.PST_NAME_PP\n",
    "working_dir = fs.WORKING_DIR_PP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs.plot_model(working_dir, pst_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Monte Carlo\n",
    "\n",
    "### In the previous pilot points Monte Carlo notebook, we saw that none of the realizations fit the observations anywhere close to ``phimlim`` because of the dimensionality of the pilot point problem.  \n",
    "\n",
    "### Here, we will use so linear algebra trickeration to \"pre-condition\" the realizations so that they have a better chance of fitting the observations. As we all know now, \"linear algebra\" = Jacobian!\n",
    "\n",
    "### First we need to run the calibration process to get the MAP parameters and last Jacobian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst = pyemu.Pst(os.path.join(working_dir,pst_name))\n",
    "# some control settings\n",
    "pst.control_data.noptmax = 5\n",
    "pst.pestpp_options[\"n_iter_base\"] = -1\n",
    "pst.pestpp_options[\"n_iter_super\"] = 3\n",
    "# adjust observation weights\n",
    "#wl_obs = [o for o in pst.nnz_obs_names if o.startswith('c')]\n",
    "#pst.observation_data.loc[wl_obs,\"weight\"] = 0.5\n",
    "# Tikhonov regularization\n",
    "pyemu.helpers.zero_order_tikhonov(pst,par_groups=[\"rch\",\"w0\",\"w1\"])\n",
    "v = pyemu.geostats.ExpVario(contribution=1.0,a=2500.0)\n",
    "gs = pyemu.geostats.GeoStruct(variograms=v,nugget=0.0)\n",
    "df_pp = pyemu.gw_utils.pp_tpl_to_dataframe(os.path.join(working_dir,\"hkpp.dat.tpl\"))\n",
    "cov = gs.covariance_matrix(df_pp.x,df_pp.y,df_pp.parnme)\n",
    "pyemu.helpers.first_order_pearson_tikhonov(pst,cov,reset=False)\n",
    "pst.reg_data.phimlim = 500\n",
    "pst.reg_data.phimaccept = 550\n",
    "pst.control_data.pestmode = \"regularization\"\n",
    "# subspace regularization\n",
    "pst.svd_data.maxsing = 2\n",
    "# save the control file and check it\n",
    "pst.write(os.path.join(working_dir,pst_name))\n",
    "pyemu.helpers.run(\"pestchek {0}\".format(pst_name),cwd=working_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "os.chdir(working_dir)\n",
    "pyemu.helpers.start_slaves('.',\"pestpp\",pst_name,num_slaves=15,master_dir='.')\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = pst.observation_data\n",
    "obs.loc[pst.nnz_obs_names,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.adjust_weights_resfile()\n",
    "obs.loc[pst.nnz_obs_names,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.phi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How does this all pan out when we run the models?\n",
    "\n",
    "Let's look at two options:  \n",
    "1. unconstrained Monte Carlo (like we did before [results were shitty!])  \n",
    "2. posterior sampling from the ``schur`` compliment "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### first, unconstrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cov = pyemu.helpers.geostatistical_prior_builder(pst,{gs:df_pp},sigma_range=6)\n",
    "mc = pyemu.MonteCarlo(jco=os.path.join(working_dir,pst_name.replace(\".pst\",\".jco\")),pst=pst,parcov=cov)\n",
    "mc.pst.parrep(os.path.join(working_dir,pst_name.replace(\".pst\",\".parb\")))\n",
    "mc.draw(num_reals=500, enforce_bounds=\"reset\",how='gaussian')\n",
    "mc.parensemble.to_csv(os.path.join(working_dir,\"sweep_in.unconst.csv\"))\n",
    "pst.pestpp_options[\"sweep_output_csv_file\"] = \"sweep_out.unconst.csv\"\n",
    "pst.pestpp_options[\"sweep_parameter_csv_file\"] = \"sweep_in.unconst.csv\"\n",
    "pst.write(os.path.join(working_dir,pst_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "os.chdir(working_dir)\n",
    "pyemu.helpers.start_slaves('.','sweep',pst_name,num_slaves=15,master_dir='.')\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### now with the ```schur``` bayesian monte carlo\n",
    "\n",
    "Here, we will swap out the prior parameter covariance matrix ($\\boldsymbol{\\Sigma}_{\\theta}$) for the FOSM-based posterior parameter covariance matrix ($\\overline{\\boldsymbol{\\Sigma}}_{\\theta}$).  Everything else is exactly the same (sounds like a NIN song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = pyemu.Schur(jco=os.path.join(working_dir,pst_name.replace(\".pst\",\".jcb\")),pst=pst,parcov=cov)\n",
    "sc.pst.parrep(os.path.join(working_dir,pst_name.replace(\".pst\",\".parb\")))\n",
    "mc = pyemu.MonteCarlo(pst=pst,parcov=sc.posterior_parameter)\n",
    "mc.draw(num_reals=500, enforce_bounds=\"reset\",how='gaussian')\n",
    "mc.parensemble.to_csv(os.path.join(working_dir,\"sweep_in.schur.csv\"))\n",
    "pst.pestpp_options[\"sweep_output_csv_file\"] = \"sweep_out.schur.csv\"\n",
    "pst.pestpp_options[\"sweep_parameter_csv_file\"] = \"sweep_in.schur.csv\"\n",
    "pst.write(os.path.join(working_dir,pst_name))\n",
    "os.chdir(working_dir)\n",
    "pyemu.helpers.start_slaves('.',\"sweep\",pst_name,num_slaves=15,master_dir='.')\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_unconst = pd.read_csv(os.path.join(working_dir,\"sweep_out.unconst.csv\"))\n",
    "df_unconst.columns = [c.lower() for c in df_unconst.columns]\n",
    "df_schur = pd.read_csv(os.path.join(working_dir,\"sweep_out.schur.csv\"))\n",
    "df_schur.columns = [c.lower() for c in df_schur.columns]\n",
    "\n",
    "acceptable_phi = 21.0\n",
    "ge_schur = df_schur.loc[df_schur.phi<acceptable_phi].index.values\n",
    "ge_unconst = df_unconst.loc[df_unconst.phi<acceptable_phi].index.values\n",
    "print(\"unconstrained good enough:{0}\".format(len(ge_unconst)))    \n",
    "print(\"schur good enough:{0}\".format(len(ge_schur))) \n",
    "df_schur.phi.hist(bins=10)\n",
    "plt.show()\n",
    "df_unconst.phi.hist(bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for forecast in mc.pst.forecast_names:\n",
    "    ax = plt.subplot(111)\n",
    "    df_unconst.loc[:,forecast].hist(ax=ax,bins=10,alpha=0.5,color=\"0.5\",normed=True,label=\"prior\") \n",
    "    df_schur.loc[ge_schur,forecast].hist(ax=ax,bins=10,alpha=0.5,color=\"b\",normed=True,label=\"posterior\")    \n",
    "    ylim = ax.get_ylim()\n",
    "    v = mc.pst.observation_data.loc[forecast,\"obsval\"]\n",
    "    ax.plot([v,v],ylim,\"k--\",lw=2.0)\n",
    "    ax.set_title(forecast)\n",
    "    ax.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We see that a fair number of realizations passed for the ``schur`` preconditioned case, while only a few passed from the unconstrainted draws from the prior. \n",
    "\n",
    "The good news...finally...we are bracketing the truth for most forecasts...whew! that's a lot of work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
