{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# and now for something completely different...\n",
    "\n",
    "### During these excersizes, we have seen a traditional parameter estimation then uncertainty analysis workflow.  We also saw for the pilot points notebooks, about 500 model runs to \"calibrate\" the model and then another 500 to 1000 to find a decent set (ensemble) of realizations that fit the data acceptably well.  \n",
    "\n",
    "### But...even using pilot points as a parameterization device is a form of regularization: ideally, we would have an HK parameter in every model cell. But, that is too expensive in terms of model runs for calibration and uncertainty analysis (at least as we have learned it so far).\n",
    "\n",
    "### However, there are some new techniques that free us from these computational constraints so that we can more efficiently use lots of parameters.  One approach to this is the iterative Ensemble Smoother form of the GLM.  It is implemented in pyemu and a C++ version is in the works.  Let's see how this technique works for the freyberg model - a special version of the freyberg model with an HK parameter in every cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os, shutil\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import numpy as np\n",
    "from IPython.display import Image\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import flopy as flopy\n",
    "import pyemu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: unit 13 of package BAS6 already in use\n",
      "****Warning -- two packages of the same type:  <class 'flopy.modflow.mfbas.ModflowBas'> <class 'flopy.modflow.mfbas.ModflowBas'>\n",
      "replacing existing Package...\n",
      "\n",
      "changing model workspace...\n",
      "   freyberg_gr\n",
      "FloPy is using the following executable to run the model: /Users/jeremyw/Dev/gw1876/activities/freyberg_grid_ies/freyberg_gr/mfnwt\n",
      "\n",
      "                                  MODFLOW-NWT-SWR1 \n",
      "    U.S. GEOLOGICAL SURVEY MODULAR FINITE-DIFFERENCE GROUNDWATER-FLOW MODEL\n",
      "                             WITH NEWTON FORMULATION\n",
      "                             Version 1.1.1, 7/21/2016                        \n",
      "                    BASED ON MODFLOW-2005 Version 1.11.0 08/08/2013                       \n",
      "\n",
      "                    SWR1 Version 1.04.0 07/21/2016                       \n",
      "\n",
      " Using NAME file: freyberg.nam \n",
      " Run start date and time (yyyy/mm/dd hh:mm:ss): 2018/03/21  8:07:17\n",
      "\n",
      " Solving:  Stress period:     1    Time step:     1    Groundwater-Flow Eqn.\n",
      " Solving:  Stress period:     2    Time step:     1    Groundwater-Flow Eqn.\n",
      " Solving:  Stress period:     3    Time step:     1    Groundwater-Flow Eqn.\n",
      " Run end date and time (yyyy/mm/dd hh:mm:ss): 2018/03/21  8:07:17\n",
      " Elapsed run time:  0.055 Seconds\n",
      "\n",
      "  Normal termination of simulation\n",
      "Util2d:delr: resetting 'how' to external\n",
      "Util2d:delc: resetting 'how' to external\n",
      "Util2d:model_top: resetting 'how' to external\n",
      "Util2d:botm_layer_0: resetting 'how' to external\n",
      "Util2d:ibound_layer_0: resetting 'how' to external\n",
      "Util2d:strt_layer_0: resetting 'how' to external\n",
      "Util2d:rech_1: resetting 'how' to external\n",
      "Util2d:rech_2: resetting 'how' to external\n",
      "Util2d:rech_3: resetting 'how' to external\n",
      "Util2d:hk layer 1: resetting 'how' to external\n",
      "Util2d:vka: resetting 'how' to external\n",
      "Util2d:ss: resetting 'how' to external\n",
      "Util2d:sy: resetting 'how' to external\n",
      "FloPy is using the following executable to run the model: /Users/jeremyw/Dev/gw1876/activities/freyberg_grid_ies/freyberg_gr/mfnwt\n",
      "\n",
      "                                  MODFLOW-NWT-SWR1 \n",
      "    U.S. GEOLOGICAL SURVEY MODULAR FINITE-DIFFERENCE GROUNDWATER-FLOW MODEL\n",
      "                             WITH NEWTON FORMULATION\n",
      "                             Version 1.1.1, 7/21/2016                        \n",
      "                    BASED ON MODFLOW-2005 Version 1.11.0 08/08/2013                       \n",
      "\n",
      "                    SWR1 Version 1.04.0 07/21/2016                       \n",
      "\n",
      " Using NAME file: freyberg.nam \n",
      " Run start date and time (yyyy/mm/dd hh:mm:ss): 2018/03/21  8:07:17\n",
      "\n",
      " Solving:  Stress period:     1    Time step:     1    Groundwater-Flow Eqn.\n",
      " Solving:  Stress period:     2    Time step:     1    Groundwater-Flow Eqn.\n",
      " Solving:  Stress period:     3    Time step:     1    Groundwater-Flow Eqn.\n",
      " Run end date and time (yyyy/mm/dd hh:mm:ss): 2018/03/21  8:07:18\n",
      " Elapsed run time:  0.064 Seconds\n",
      "\n",
      "  Normal termination of simulation\n",
      "Starting to read HYDMOD data from freyberg.hyd.bin\n",
      "Starting to read HYDMOD data from freyberg.hyd.bin.truth\n",
      "writing 'sfr_obs.config' to sfr_obs.config\n",
      "                                    obsnme     obsval  weight    obgnme\n",
      "c001fr05c04_19791231  c001fr05c04_19791231  37.727573     0.0  forehead\n",
      "c001fr16c17_19791231  c001fr16c17_19791231  35.188260     0.0  forehead\n"
     ]
    }
   ],
   "source": [
    "import freyberg_setup as fs\n",
    "fs.setup_pest_gr()\n",
    "working_dir = fs.WORKING_DIR_GR\n",
    "pst_name = fs.PST_NAME_GR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parnme</th>\n",
       "      <th>partrans</th>\n",
       "      <th>parchglim</th>\n",
       "      <th>parval1</th>\n",
       "      <th>parlbnd</th>\n",
       "      <th>parubnd</th>\n",
       "      <th>pargp</th>\n",
       "      <th>scale</th>\n",
       "      <th>offset</th>\n",
       "      <th>dercom</th>\n",
       "      <th>extra</th>\n",
       "      <th>i</th>\n",
       "      <th>j</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parnme</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>r1_i00_j00</th>\n",
       "      <td>r1_i00_j00</td>\n",
       "      <td>log</td>\n",
       "      <td>factor</td>\n",
       "      <td>0.00009</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>r1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>9875.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r1_i00_j01</th>\n",
       "      <td>r1_i00_j01</td>\n",
       "      <td>log</td>\n",
       "      <td>factor</td>\n",
       "      <td>0.00009</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>r1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>375.0</td>\n",
       "      <td>9875.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r1_i00_j02</th>\n",
       "      <td>r1_i00_j02</td>\n",
       "      <td>log</td>\n",
       "      <td>factor</td>\n",
       "      <td>0.00009</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>r1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>625.0</td>\n",
       "      <td>9875.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r1_i00_j03</th>\n",
       "      <td>r1_i00_j03</td>\n",
       "      <td>log</td>\n",
       "      <td>factor</td>\n",
       "      <td>0.00009</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>r1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>875.0</td>\n",
       "      <td>9875.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r1_i00_j04</th>\n",
       "      <td>r1_i00_j04</td>\n",
       "      <td>log</td>\n",
       "      <td>factor</td>\n",
       "      <td>0.00009</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>r1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1125.0</td>\n",
       "      <td>9875.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                parnme partrans parchglim  parval1   parlbnd   parubnd pargp  \\\n",
       "parnme                                                                         \n",
       "r1_i00_j00  r1_i00_j00      log    factor  0.00009  0.000081  0.000099    r1   \n",
       "r1_i00_j01  r1_i00_j01      log    factor  0.00009  0.000081  0.000099    r1   \n",
       "r1_i00_j02  r1_i00_j02      log    factor  0.00009  0.000081  0.000099    r1   \n",
       "r1_i00_j03  r1_i00_j03      log    factor  0.00009  0.000081  0.000099    r1   \n",
       "r1_i00_j04  r1_i00_j04      log    factor  0.00009  0.000081  0.000099    r1   \n",
       "\n",
       "            scale  offset  dercom  extra  i  j       x       y  \n",
       "parnme                                                          \n",
       "r1_i00_j00    1.0     0.0       1    NaN  0  0   125.0  9875.0  \n",
       "r1_i00_j01    1.0     0.0       1    NaN  0  1   375.0  9875.0  \n",
       "r1_i00_j02    1.0     0.0       1    NaN  0  2   625.0  9875.0  \n",
       "r1_i00_j03    1.0     0.0       1    NaN  0  3   875.0  9875.0  \n",
       "r1_i00_j04    1.0     0.0       1    NaN  0  4  1125.0  9875.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = flopy.modflow.Modflow.load(fs.MODEL_NAM,model_ws=working_dir,load_only=[\"upw\"],check=False)\n",
    "pst = pyemu.Pst(os.path.join(working_dir,pst_name))\n",
    "obs = pst.observation_data\n",
    "obs.loc[obs.obgnme==\"calhead\",\"weight\"] = 0.75\n",
    "par = pst.parameter_data\n",
    "hk_par = par.loc[par.pargp==\"hk\"].copy()\n",
    "hk_par.loc[:,\"i\"] = hk_par.parnme.apply(lambda x: int(x.split('_')[1][1:]))\n",
    "hk_par.loc[:,\"j\"] = hk_par.parnme.apply(lambda x: int(x.split('_')[2][1:]))\n",
    "hk_par.loc[:,\"x\"] = m.sr.xcentergrid[hk_par.i,hk_par.j]\n",
    "hk_par.loc[:,\"y\"] = m.sr.ycentergrid[hk_par.i,hk_par.j]\n",
    "hk_par.head()\n",
    "\n",
    "r0_par = par.loc[par.pargp==\"r0\"].copy()\n",
    "r0_par.loc[:,\"i\"] = r0_par.parnme.apply(lambda x: int(x.split('_')[1][1:]))\n",
    "r0_par.loc[:,\"j\"] = r0_par.parnme.apply(lambda x: int(x.split('_')[2][1:]))\n",
    "r0_par.loc[:,\"x\"] = m.sr.xcentergrid[r0_par.i,r0_par.j]\n",
    "r0_par.loc[:,\"y\"] = m.sr.ycentergrid[r0_par.i,r0_par.j]\n",
    "r0_par.head()\n",
    "\n",
    "r1_par = par.loc[par.pargp==\"r1\"].copy()\n",
    "r1_par.loc[:,\"i\"] = r1_par.parnme.apply(lambda x: int(x.split('_')[1][1:]))\n",
    "r1_par.loc[:,\"j\"] = r1_par.parnme.apply(lambda x: int(x.split('_')[2][1:]))\n",
    "r1_par.loc[:,\"x\"] = m.sr.xcentergrid[r1_par.i,r1_par.j]\n",
    "r1_par.loc[:,\"y\"] = m.sr.ycentergrid[r1_par.i,r1_par.j]\n",
    "r1_par.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'number of parameters: 2413 : WTF!'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"number of parameters: {0} : WTF!\".format(pst.npar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.chdir(working_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First we create an ``EnsembleSmoother`` instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pst.filename = pst_name\n",
    "ies = pyemu.EnsembleSmoother(pst=pst,num_slaves=15,slave_dir=\".\",port=4005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ``EnsembleSmoother.initialize()`` does lots of things for you:\n",
    "### - make draws from parcov for the initial ``ParameterEnsemble``\n",
    "### - make draws from obscov for the \"target\" ``ObservationEnsemble``\n",
    "### - runs the initial ``ParameterEnsemble`` forward to get the initial ``ObservationEnsemble``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ies.initialize(num_reals=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# So what we just did was essentially an unconstrained Monte Carlo with 100 realizations - that's nothing new..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's visualize the first few ``hk`` fields - drawn from prior (uncalibrated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for real in ies.parensemble.index[:4]:\n",
    "    arr = np.zeros((m.nrow,m.ncol))\n",
    "    arr[hk_par.i,hk_par.j] = ies.parensemble.loc[real,hk_par.parnme]\n",
    "    m.upw.hk[0] = arr\n",
    "    m.upw.hk[0].plot(alpha=0.5,colorbar=True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Those don't look very \"geologic\" - why? Answer: the Prior! (its always about the Prior)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's visualize the distributions (histograms) for each of the forecasts\n",
    "\n",
    "### These distributions come from running the initial (uncalibrated) parameter ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_obs = ies.obsensemble.copy()\n",
    "for forecast in pst.forecast_names:\n",
    "    ax = ies.obsensemble.loc[:,forecast].hist(bins=10)\n",
    "    ax.set_title(forecast)\n",
    "    ylim = ax.get_ylim()\n",
    "    v = ies.pst.observation_data.loc[forecast,\"obsval\"]\n",
    "    ax.plot([v,v],ylim,\"k--\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The initial (uncalibrated) phi distribution...not so good..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ies.current_phi.hist(bins=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Since we only have a few observations we are trying to match, we can look at there distributions also.  The \"blue\" histogram is the results of the initial parameter ensemble evaluation.  The \"red\" is the \"target\" distribution: each observation has a unique value for each realization: the observed value + a realization of measurement noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.nnz_obs_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for oname in pst.nnz_obs_names:\n",
    "    ax = ies.obsensemble_0.loc[:,oname].hist(bins=10,alpha=0.5,color='r')\n",
    "    ies.obsensemble.loc[:,oname].hist(bins=10,ax=ax,alpha=0.5,color='b')\n",
    "    ax.set_title(oname)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ``EnsembleSmoother.update()`` propagates the ensemble forward, updating the ``ParameterEnsemble`` through the GLM algorithm, then runs the new ``ParameterEnsemble``.  In other words, we are going to use an approximate (low fidelity) Jacobian to update the entire parameter ensemble, the we are going to run another Monte Carlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ies.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's see how phi is doing..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ies.current_phi.hist(bins=10)\n",
    "plt.show()\n",
    "ies.current_phi.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notice how much the ``phi`` distribution has decreased compared to the initialized ``EnsembleSmoother``: Nice!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's run through a few more updates...and plot the phi distribution each time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "    ies.update()\n",
    "    phi = ies.current_phi\n",
    "    ax = plt.subplot(111)\n",
    "    phi.hist(bins=10,ax=ax)\n",
    "    ax.set_title(\"iteration:{0}, total model runs:{1}, avg phi:{2}\".format(ies.iter_num,ies.total_runs,phi.mean()))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Holy Crap!  phi has gotten really good after only a 400ish runs of the model - remember, there over 800 parameters. Let's see how the forecasts are doing..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for forecast in pst.forecast_names:\n",
    "    ax = ies.obsensemble.loc[:,forecast].hist(bins=10,color='b',alpha=0.5)\n",
    "    init_obs.loc[:,forecast].hist(bins=10,ax=ax,color='g',alpha=0.5)\n",
    "    ax.set_title(forecast)\n",
    "    ylim = ax.get_ylim()\n",
    "    v = ies.pst.observation_data.loc[forecast,\"obsval\"]\n",
    "    ax.plot([v,v],ylim,\"k--\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ies.total_runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sum = pd.read_csv(pst_name+\".iobj.csv\")\n",
    "df_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.subplot(111)\n",
    "real_cols = [c for c in df_sum.columns if c.startswith(\"0\")]\n",
    "[ax.plot(df_sum.total_runs,df_sum.loc[:,rc],'0.5',lw=0.25) for rc in real_cols]\n",
    "ax.plot(df_sum.total_runs,df_sum.loc[:,\"mean\"],\"k\",lw=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Awesome!  We are crushing phi...but how to the parameter fields looks?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for real in ies.parensemble.index[:4]:\n",
    "    arr = np.zeros((m.nrow,m.ncol))\n",
    "    arr[hk_par.i,hk_par.j] = ies.parensemble.loc[real,hk_par.parnme]\n",
    "    m.upw.hk[0] = arr\n",
    "    m.upw.hk[0].plot(alpha=0.5,colorbar=True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uh oh. The fields look like noise...how can we fix this? Solution: a full covariance matrix that expresses spatial correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# iES with a full covariance matrix\n",
    "\n",
    "## Now let's rerun the iES process but with a full, geostatistical prior covariance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "v = pyemu.geostats.ExpVario(contribution=1.0,a=2500.0)\n",
    "gs = pyemu.geostats.GeoStruct(variograms=v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cov = pyemu.helpers.geostatistical_prior_builder(pst=pst,struct_dict={gs:[r1_par,hk_par]},sigma_range=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's see how this covariance looks compare to the one we used previously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cov.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(cov.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(ies.parcov.as_2d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we create a new ``iES`` and update 3 times..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ies = pyemu.EnsembleSmoother(pst=pst,num_slaves=15,slave_dir=\".\",parcov=cov,port=4005)\n",
    "ies.initialize(num_reals=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's visual the new parameter fields:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for real in ies.parensemble.index[:4]:\n",
    "    arr = np.zeros((m.nrow,m.ncol))\n",
    "    arr[hk_par.i,hk_par.j] = ies.parensemble.loc[real,hk_par.parnme]\n",
    "    m.upw.hk[0] = arr\n",
    "    m.upw.hk[0].plot(alpha=0.5,colorbar=True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Those fields look much more \"geologic\" (what ever that means)...let's see how well the smoother does with these fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(3):\n",
    "    ies.update()\n",
    "    phi = ies.current_phi\n",
    "    ax = plt.subplot(111)\n",
    "    phi.hist(bins=10,ax=ax)\n",
    "    ax.set_title(\"iteration:{0}, total model runs:{1}\".format(ies.iter_num,ies.total_runs))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### phi looks really good still...let's see how the final (calibrated) parameter fields look...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for real in ies.parensemble.index[:4]:\n",
    "    arr = np.zeros((m.nrow,m.ncol))\n",
    "    arr[hk_par.i,hk_par.j] = ies.parensemble.loc[real,hk_par.parnme]\n",
    "    m.upw.hk[0] = arr\n",
    "    m.upw.hk[0].plot(alpha=0.5,colorbar=True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for forecast in pst.forecast_names:\n",
    "    ax = ies.obsensemble.loc[:,forecast].hist(bins=15,color='b',alpha=0.5,label=\"posterior\",normed=True)\n",
    "    init_obs.loc[:,forecast].hist(bins=15,color=\"0.5\",alpha=0.5,label=\"prior\",normed=True)\n",
    "    ax.set_title(forecast)\n",
    "    ylim = ax.get_ylim()\n",
    "    v = ies.pst.observation_data.loc[forecast,\"obsval\"]\n",
    "    ax.plot([v,v],ylim,\"k--\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We see that the final (posterior) ensemble is bracketing the \"truth\" for all forecasts...yeah! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
