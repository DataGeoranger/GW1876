{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data worth and related assessments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will use outputs from previous notebooks (in particular `pestpp-glm_part1.ipynb`) to undertake data worth assessments based on first-order second-moment (FOSM) techniques. \"Worth\" is framed here in the context of the extent to which the uncertainty surrounding a model prediction of management interest is reduced through data collection.  Given that these anayses can help target and optimize data acquisition strategies, this is a concept that really resonates with decision makers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "plt.rcParams['font.size']=12\n",
    "import flopy\n",
    "import pyemu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_d = \"master_glm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst = pyemu.Pst(os.path.join(m_d,\"freyberg_pp.pst\"))\n",
    "print(pst.npar_adj)\n",
    "pst.write_par_summary_table(filename=\"none\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first ingredient: parameter covariance matrix (representing prior uncertainty in this instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov = pyemu.Cov.from_binary(os.path.join(m_d,\"prior_cov.jcb\")).to_dataframe()\n",
    "cov = cov.loc[pst.adj_par_names,pst.adj_par_names]\n",
    "cov = pyemu.Cov.from_dataframe(cov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "second ingredient: jacobian matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jco = os.path.join(m_d,\"freyberg_pp.jcb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the third ingredient--the (diagonal) noise covariance matrix--populated on-the-fly using weights when constructing the Schur object below..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = pyemu.Schur(jco=jco,parcov=cov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### there we have it--all computations done and contained within `sc`.  We will only be required to access different parts of `sc` below...\n",
    "\n",
    "### Parameter uncertainty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's inspect the (approx) posterior parameter covariance matrix and the reduction in parameter uncertainty through \"data assimilation\", before mapping to forecasts... (note that this matrix is ${\\it not}$ forecast-specific)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.posterior_parameter.to_dataframe().sort_index(axis=1).iloc[100:105:,100:105]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the posterior variance for each parameter along the diagonal. The off-diags are symmetric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par_sum = sc.get_parameter_summary().sort_values(\"percent_reduction\",ascending=False)\n",
    "par_sum.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par_sum.loc[par_sum.index[:15],\"percent_reduction\"].plot(kind=\"bar\",color=\"turquoise\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What have we achieved by \"notionally calibrating\" our model to 13 head and 1 stream flow observations? Which parameters are informed? Will they matter for the forecast of interest? Which ones are un-informed?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecast uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecasts = sc.pst.pestpp_options['forecasts'].split(\",\")\n",
    "forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sc.get_forecast_summary()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a pretty plot \n",
    "fig = plt.figure()\n",
    "ax = plt.subplot(111)\n",
    "ax = df[\"percent_reduction\"].plot(kind='bar',ax=ax,grid=True)\n",
    "ax.set_ylabel(\"percent uncertainy\\nreduction from calibration\")\n",
    "ax.set_xlabel(\"forecast\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surprise, surprise... Some forecasts benefit from calibration, some do not! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before moving onto data worth, let's look at the contribution of different parameters to forecast uncertainty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameter contributions to uncertainty are quantified by \"fixing\" parameters (or parameter groups) and observing the uncertainty reduction as a result. This approach is of course subject to some sizable assumptions--related to parameter representativeness. But it can be very informative. Let's do by group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par_contrib = sc.get_par_group_contribution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par_contrib.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = par_contrib.loc[\"base\",:]\n",
    "par_contrib = 100.0 * (base - par_contrib) / par_contrib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for forecast in par_contrib.columns:\n",
    "    fore_df = par_contrib.loc[:,forecast].copy()\n",
    "    fore_df.sort_values(inplace=True, ascending=False)\n",
    "    ax = fore_df.iloc[:10].plot(kind=\"bar\",color=\"b\")\n",
    "    ax.set_title(forecast)\n",
    "    ax.set_ylabel(\"percent variance reduction\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data worth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### what is the worth of ${\\it existing}$ observations?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is happening under the hood is that we are recalculating the Schur complement without some of the observations to see how the posterior forecast uncertainty increases (wrt a \"base\" condition in which we have all observation data available)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dw_rm = sc.get_removed_obs_importance()\n",
    "dw_rm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the ``base`` row contains the results of the Schur complement calculation (in terms of forecast uncertainty variance) using all observations.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's normalize to make more meaningful comparisons of data worth (unctainty variance reduction)\n",
    "base = dw_rm.loc[\"base\",:]\n",
    "dw_rm = 100 * (dw_rm  - base) / base\n",
    "dw_rm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for forecast in dw_rm.columns:\n",
    "    fore_df = dw_rm.loc[:,forecast].copy()\n",
    "    fore_df.sort_values(inplace=True, ascending=False)\n",
    "    ax = fore_df.iloc[:10].plot(kind=\"bar\",color=\"b\")\n",
    "    ax.set_title(forecast)\n",
    "    ax.set_ylabel(\"percent variance increase\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is also an option to calculate the worth of observations by taking a \"base\" condition of zero observation (i.e., a priori) and calculating the reduction in uncertainty through adding observations to the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dw_ad = sc.get_added_obs_importance()\n",
    "base = dw_ad.loc[\"base\",:]\n",
    "dw_ad = 100 * (base - dw_ad) / base\n",
    "for forecast in dw_ad.columns:\n",
    "    fore_df_ad = dw_ad.loc[:,forecast].copy()\n",
    "    fore_df_ad.sort_values(inplace=True, ascending=False)\n",
    "    ax = fore_df_ad.iloc[:10].plot(kind=\"bar\",color=\"b\")\n",
    "    ax.set_title(forecast)\n",
    "    ax.set_ylabel(\"percent variance decrease\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do these two approaches give the same answer? They shouldn't.. Why? Let's discuss.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### what is the worth of ${\\it potential}$ observations? what data should we collect?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall we are \"carrying\" cell-by-cell heads, reach-based sfr flows, etc.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_obs = pst.observation_data.loc[(pst.observation_data.weight == 0),\"obsnme\"].tolist()\n",
    "z_obs = [x for x in z_obs if x not in forecasts]  # less our forecasts\n",
    "z_obs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can therefore repeat above analysis for the observations that currently have zero weight by turning those observations \"on\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Beware: calculating the Schur complement for all potential observation types and locations could take some time!! So we will sample to speed things up. You may need to further reduce the number of potential obs - you can do this by adding [0::2] to take every second element for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_obs = [x for x in z_obs if \"hds_00\" in x and x.endswith(\"_000\")]  # all heads in top layer in first stress period\n",
    "print(\"number of new potential head observation locations considered: {}\".format(len(new_obs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "start = datetime.now()\n",
    "df_worth_new = sc.get_added_obs_importance(obslist_dict=new_obs, base_obslist=sc.pst.nnz_obs_names, reset_zero_weight=True)\n",
    "print(\"took:\",datetime.now() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_worth_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nice! now let's process a little bit and make some plots of (potential) data worth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def worth_plot_prep(df):\n",
    "    # some processing\n",
    "    df_new_base = df.loc[\"base\",:].copy()  # \"base\" row\n",
    "    df_new_imax = df.apply(lambda x: df_new_base - x, axis=1).idxmax()  # obs with largest unc red for each pred\n",
    "    df_new_worth = 100.0 * (df.apply(lambda x: df_new_base - x, axis=1) / df_new_base)  # normalizing like above\n",
    "    \n",
    "    # plot prep\n",
    "    df_new_worth_plot = df_new_worth[df_new_worth.index != 'base'].copy()\n",
    "    df_new_worth_plot.loc[:,'names'] = df_new_worth_plot.index\n",
    "    names = df_new_worth_plot.names\n",
    "    df_new_worth_plot.loc[:,\"i\"] = names.apply(lambda x: int(x[8:10]))\n",
    "    df_new_worth_plot.loc[:,\"j\"] = names.apply(lambda x: int(x[11:14]))\n",
    "    df_new_worth_plot.loc[:,'kper'] = names.apply(lambda x: int(x[-3:]))\n",
    "    #df_new_worth_plot.head()\n",
    "    \n",
    "    return df_new_worth_plot, df_new_imax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_worth_new_plot, df_worth_new_imax = worth_plot_prep(df_worth_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_worth_new_plot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_worth_new_imax  # which obs causes largest unc var reduction?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_worth_new_plot.drop(axis=1,labels=[\"part_status\"],inplace=True) # drop \"part_status\"\n",
    "df_worth_new_plot.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_added_importance(df_worth_plot, ml, forecast_name=None, \n",
    "                          newlox=None,figsize=(12,7)):\n",
    "\n",
    "    vmax = df_worth_plot[forecast_name].max()\n",
    "    #vmax = df_worth_plot[forecast_name].max()\n",
    "    \n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    axlist = []\n",
    "    # if new locations provided, plot them with their numbers\n",
    "    if newlox:\n",
    "        currx = []\n",
    "        curry = []\n",
    "        for i,clox in enumerate(newlox):\n",
    "            crow = int(clox[8:10])\n",
    "            ccol = int(clox[11:14])\n",
    "            currx.append(ml.sr.xcentergrid[crow,ccol])\n",
    "            curry.append(ml.sr.ycentergrid[crow,ccol])\n",
    "\n",
    "    for SP in range(1):\n",
    "        unc_array = np.zeros_like(ml.upw.hk[0].array) - 1\n",
    "        df_worth_csp = df_worth_plot.groupby('kper').get_group(SP)\n",
    "        for i,j,unc in zip(df_worth_csp.i,df_worth_csp.j,\n",
    "                           df_worth_csp[forecast_name]):\n",
    "            unc_array[i,j] = unc \n",
    "        unc_array[unc_array == -1] = np.NaN\n",
    "        axlist.append(plt.subplot(111,aspect=\"equal\"))\n",
    "        cb = axlist[-1].imshow(unc_array,interpolation=\"nearest\",\n",
    "                               alpha=0.5,extent=ml.sr.get_extent(), \n",
    "                               vmin=0, vmax=vmax)\n",
    "        if SP==0:\n",
    "            plt.colorbar(cb,label=\"percent uncertainty reduction\")\n",
    "        \n",
    "        # plot sfr\n",
    "        #axlist[-1].scatter([14 for x in range(ml.nrow)],[x for x in range(ml.nrow)],marker='d',s=60)\n",
    "        #axlist[-1].scatter([10],[10],marker='d',s=50,zorder=0)\n",
    "        #ml.sfr.stress_period_data.plot(key=\"ireach\",axes=[axlist[-1]])\n",
    "       \n",
    "        # plot the pumping wells\n",
    "        #ml.wel.stress_period_data.plot(kper=1,mflay=2)\n",
    "\n",
    "        if newlox:\n",
    "            for i,(cx,cy,cobs) in enumerate(zip(currx, curry, newlox)):\n",
    "                csp = int(cobs[-1])\n",
    "                if csp == SP:\n",
    "                    axlist[-1].plot(cx, cy, 'rd', mfc=None, ms=18, alpha=0.8)\n",
    "                    axlist[-1].text(cx-50,cy-50,i, size='medium')\n",
    "                \n",
    "        # plot the location of the forecast if possible\n",
    "        if forecast_name.startswith('hds'):\n",
    "            i = int(forecast_name[8:10])\n",
    "            j = int(forecast_name[11:14])\n",
    "            forecast_x = ml.sr.xcentergrid[i,j]\n",
    "            forecast_y = ml.sr.ycentergrid[i,j]\n",
    "            axlist[-1].scatter(forecast_x, forecast_y, marker='o', s=600, \n",
    "                               alpha=0.5)\n",
    "\n",
    "        plt.title('data worth for {0}'.format(forecast_name))\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = flopy.modflow.Modflow.load(\"freyberg.nam\", model_ws=os.path.join(m_d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_worth_new_plot['hds_00_013_002_001'].idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [x for x in forecasts if \"part_status\" not in x]:\n",
    "    fig = plot_added_importance(df_worth_plot=df_worth_new_plot, ml=m, \n",
    "                                forecast_name=i)\n",
    "    #fig.savefig('add_worth_{}.pdf'.format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"next most\" important observation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is what we would ultimately like to know... Takes into account what we already know through incrementally making additional observations. For example, consider making an observation in the middle of the zone of highest worth. Where should we subsequently collect data? \n",
    "\n",
    "Let's just use the same potential observation list for now (the head in every top-layer cell) and evaluate which ones to collect, if we only had the budget for 5, in the context of the particle travel time prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.now()\n",
    "next_most_df = sc.next_most_important_added_obs(forecast='part_time',niter=5,obslist_dict=dict(zip(new_obs,new_obs)),\n",
    "                                                base_obslist=sc.pst.nnz_obs_names,reset_zero_weight=True)\n",
    "print(\"took:\",datetime.now() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_most_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_added_importance(df_worth_new_plot, m, 'part_time', \n",
    "                            newlox=next_most_df.best_obs.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for fun after class\n",
    "for i in [x for x in forecasts if \"part_status\" not in x]:\n",
    "    next_most_df = sc.next_most_important_added_obs(forecast=i,niter=5,obslist_dict=dict(zip(new_obs,new_obs)),\n",
    "                                                    base_obslist=sc.pst.nnz_obs_names,reset_zero_weight=True)\n",
    "    fig = plot_added_importance(df_worth_new_plot, m, forcast_name=i, \n",
    "                                newlox=next_most_df.best_obs.tolist())\n",
    "    fig.savefig('next_best_5_worth_{}.pdf'.format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: an important assumption underpinning the above is that the model is able to fit observations to a level that is commensurate with measurement noise... Are we comfortable with this assumption? We will discuss this more in `pestpp-glm_part2.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recall...\n",
    "pst.observation_data.loc[pst.nnz_obs_names,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## an \"extra\": parameter identifiability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
