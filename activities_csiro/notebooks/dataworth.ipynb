{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data worth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will use outputs from previous notebooks (in particular `pestpp-glm_part1.ipynb`) to undertake data worth assessments based on first-order second-moment (FOSM) techniques. \"Worth\" is framed here in the context of the extent to which the uncertainty surrounding a model prediction of management interest is reduced through data collection.  Given that these anayses can help target and optimize data acquisition strategies, this is a concept that really resonates with decision makers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "plt.rcParams['font.size']=12\n",
    "import flopy\n",
    "import pyemu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_d = \"master_glm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst = pyemu.Pst(os.path.join(m_d,\"freyberg_pp.pst\"))\n",
    "print(pst.npar_adj)\n",
    "pst.write_par_summary_table(filename=\"none\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### first ingredient: parameter covariance matrix (representing prior uncertainty in this instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov = pyemu.Cov.from_binary(os.path.join(m_d,\"prior_cov.jcb\")).to_dataframe()\n",
    "cov = cov.loc[pst.adj_par_names,pst.adj_par_names]\n",
    "cov = pyemu.Cov.from_dataframe(cov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### second ingredient: jacobian matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jco = os.path.join(m_d,\"freyberg_pp.jcb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### the third ingredient--the (diagonal) noise covariance matrix--populated on-the-fly using weights when constructing the Schur object below..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = pyemu.Schur(jco=jco,parcov=cov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## there we have it--all computations done and contained within `sc`.  We will only be required to access different parts of `sc` below...\n",
    "\n",
    "## Parameter uncertainty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's inspect the (approx) posterior parameter covariance matrix and the reduction in parameter uncertainty through \"data assimilation\", before mapping to forecasts... (note that this matrix is ${\\it not}$ forecast-specific)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.posterior_parameter.to_dataframe().sort_index(axis=1).iloc[100:105:,100:105]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the posterior variance for each parameter along the diagonal. The off-diags are symmetric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par_sum = sc.get_parameter_summary().sort_values(\"percent_reduction\",ascending=False)\n",
    "par_sum.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par_sum.loc[par_sum.index[:15],\"percent_reduction\"].plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What have we achieved by \"notionally calibrating\" our model to 13 head and 1 stream flow observations? Which parameters are informed? Will they matter for the forecast of interest? Which ones are un-informed?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecast uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sc.get_forecast_summary()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[:,\"percent_reduction\"].dropna()\n",
    "df.plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### one of important assumptions we have made is that the model is able to fit observations to a level that is commensurate with measurement noise... Are we comfortable with this assumption? We will discuss this more in `pestpp-glm_part2.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recall...\n",
    "pst.observation_data.loc[pst.nnz_obs_names,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Related to the worth of observation data is the worth of parameter knowledge or \"measurement\". We quantify the worth of knowing parameters by calculating the parameter contributions to by \"fixing\" individual parameters or parameter groups and quantifying the uncertainty reduction as a result. Let's do by group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sc.get_par_group_contribution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par_contrib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = df.loc[\"base\",:]\n",
    "df = 100.0 * (base - df) / base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for forecast in df.columns:\n",
    "    fore_df = df.loc[:,forecast].copy()\n",
    "    fore_df.sort_values(inplace=True, ascending=False)\n",
    "    ax = fore_df.iloc[:10].plot(kind=\"bar\")\n",
    "    ax.set_title(forecast)\n",
    "    ax.set_ylabel(\"percent variance reduction\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sc.get_removed_obs_importance()\n",
    "base = df.loc[\"base\",:]\n",
    "df = 100 * (df - base) / base\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for forecast in df.columns:\n",
    "    fore_df = df.loc[:,forecast].copy()\n",
    "    fore_df.sort_values(inplace=True, ascending=False)\n",
    "    ax = fore_df.iloc[:10].plot(kind=\"bar\")\n",
    "    ax.set_title(forecast)\n",
    "    ax.set_ylabel(\"percent variance increase\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sc.get_added_obs_importance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### toward optimizing data acquisition: what data should we collect "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## an extra: parameter identifiability"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
