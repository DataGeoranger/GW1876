{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run PESTPP-OPT\n",
    "\n",
    "In this notebook we will setup and solve a mgmt optimization problem around how much groundwater can be pumped while maintaining sw-gw exchange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "plt.rcParams['font.size']=12\n",
    "import flopy\n",
    "import pyemu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_d = \"template\"\n",
    "m_d = \"master_opt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst = pyemu.Pst(os.path.join(t_d,\"freyberg.pst\"))\n",
    "pst.write_par_summary_table(filename=\"none\").sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define our decision varible group and also set some ++args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.pestpp_options = {}\n",
    "#dvg = [\"welflux_k02\",\"welflux\"]\n",
    "dvg = [\"welflux_k02\"]\n",
    "pst.pestpp_options[\"opt_dec_var_groups\"] = dvg\n",
    "pst.pestpp_options[\"opt_direction\"] = \"max\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the first run, we wont use chance constraints, so just fix all non-decision-variable parameter.  We also need to set some realistic bounds on the `welflux` multiplier decision variables.  Finally, we need to specify a larger derivative increment for the decision varible group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par = pst.parameter_data\n",
    "par.loc[:,\"partrans\"] = \"fixed\"\n",
    "\n",
    "#turn off pumping in the scenario\n",
    "par.loc[\"welflux_001\",\"parlbnd\"] = 0.0 \n",
    "par.loc[\"welflux_001\",\"parval1\"] = 0.0 \n",
    "dvg_pars = par.loc[par.pargp.apply(lambda x: x in dvg),\"parnme\"]\n",
    "par.loc[dvg_pars,\"partrans\"] = \"none\"\n",
    "par.loc[dvg_pars,\"parlbnd\"] = 0.0\n",
    "par.loc[dvg_pars,\"parubnd\"] = 2.0\n",
    "par.loc[dvg_pars,\"parval1\"] = 1.0\n",
    "\n",
    "pst.rectify_pgroups()\n",
    "pst.parameter_groups.loc[dvg,\"inctyp\"] = \"absolute\"\n",
    "pst.parameter_groups.loc[dvg,\"inctyp\"] = \"absolute\"\n",
    "pst.parameter_groups.loc[dvg,\"derinc\"] = 0.25\n",
    "\n",
    "pst.parameter_groups.loc[dvg,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define constraints\n",
    "\n",
    "model-based constraints are identified in pestpp-opt by an obs group that starts with \"less_than\" or \"greater_than\" and a weight greater than zero.  So first, we turn off all of the weights and get names for the sw-gw exchange observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = pst.observation_data\n",
    "obs.loc[:,\"weight\"] = 0.0\n",
    "swgw_hist = obs.loc[obs.obsnme.apply(lambda x: \"fa\" in x and( \"hw\" in x or \"tw\" in x)),\"obsnme\"]\n",
    "obs.loc[swgw_hist,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to change the obs group (`obgnme`) so that `pestpp-opt` will recognize these two model outputs as constraints.  The `obsval` becomes the RHS of the constraint.  We also need to set a lower bound constraint on the total abstraction rate (good thing we included all those list file budget components as observations!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs.loc[swgw_hist,\"obgnme\"] = \"less_than\"\n",
    "obs.loc[swgw_hist,\"weight\"] = 1.0\n",
    "\n",
    "obs.loc[swgw_hist,\"obsval\"] = -300\n",
    "\n",
    "tot_abs_rate = [\"flx_wells_19791230\"]#,\"flx_wells_19801229\"]\n",
    "obs.loc[tot_abs_rate,\"obgnme\"] = \"less_than\"\n",
    "obs.loc[tot_abs_rate,\"weight\"] = 1.0\n",
    "obs.loc[tot_abs_rate,\"obsval\"] = -600.0\n",
    "pst.less_than_obs_constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.control_data.noptmax = 1\n",
    "pst.write(os.path.join(t_d,\"freyberg_opt.pst\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyemu.os_utils.start_slaves(t_d,\"pestpp-opt\",\"freyberg_opt.pst\",num_slaves=10,master_dir=m_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load and inspect the response matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jco = pyemu.Jco.from_binary(os.path.join(m_d,\"freyberg_opt.1.jcb\")).to_dataframe().loc[pst.less_than_obs_constraints,:]\n",
    "jco"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also load the optimal decision variable values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par_df = pyemu.pst_utils.read_parfile(os.path.join(m_d,\"freyberg_opt.1.par\"))\n",
    "print(par_df.loc[dvg_pars,\"parval1\"].sum())\n",
    "par_df.loc[dvg_pars,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sum of these values is the optimal objective function value. However, since these are just mulitpliers on the pumping rate, this number isnt too meaningful. Instead, lets look at the residuals file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst = pyemu.Pst(os.path.join(m_d,\"freyberg_opt.pst\"),resfile=os.path.join(m_d,\"freyberg_opt.1.rei\"))\n",
    "pst.res.loc[pst.nnz_obs_names,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sweet as!  lots of room in the optimization problem.  The bounding constraint is the one closest to its RHS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opt under uncertainty part 1: FOSM chance constraints\n",
    "\n",
    "This is where the process of uncertainty quantification/history matching and mgmt optimizatiom meet - worlds collide! \n",
    "\n",
    "Mechanically, in PESTPP-OPT, to activate the chance constraint process, we need to specific a risk != 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.pestpp_options[\"opt_risk\"] = 0.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the FOSM-based chance constraints, we also need to have at least one adjustable non-dec-var parameter so that we can propogate parameter uncertainty to model-based constraints (this can also be posterior FOSM is non-constraint, non-zero-weight observations are specified).  For this simple demo, lets just use the constant multiplier parameters in the prior uncertainty stance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cn_pars = par.loc[par.pargp.apply(lambda x: \"cn\" in x),\"parnme\"]\n",
    "cn_pars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par = pst.parameter_data\n",
    "par.loc[cn_pars,\"partrans\"] = \"log\"\n",
    "pst.control_data.noptmax = 1\n",
    "pst.write(os.path.join(t_d,\"freyberg_opt_uu1.pst\"))\n",
    "pst.npar_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyemu.os_utils.start_slaves(t_d,\"pestpp-opt\",\"freyberg_opt_uu1.pst\",num_slaves=20,master_dir=m_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst = pyemu.Pst(os.path.join(m_d,\"freyberg_opt_uu1.pst\"),resfile=os.path.join(m_d,\"freyberg_opt_uu1.1.rei\"))\n",
    "pst.res.loc[pst.nnz_obs_names,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par_df = pyemu.pst_utils.read_parfile(os.path.join(m_d,\"freyberg_opt_uu1.1.par\"))\n",
    "print(par_df.loc[dvg_pars,\"parval1\"].sum())\n",
    "par_df.loc[dvg_pars,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opt under uncertainty part 2: ensemble-based chance constraints\n",
    "\n",
    "PESTPP-OPT can also skip the FOSM calculations if users specify model-based constraint weights as standard deviations.  These can be derived from existing ensembles (oh snap!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_df = pd.read_csv(os.path.join(\"master_prior_sweep\",\"sweep_out.csv\"),index_col=0)\n",
    "obs_df = obs_df.loc[obs_df.failed_flag==0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_std = obs_df.std().loc[pst.nnz_obs_names]\n",
    "pr_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wait!  Something is wrong here:  The cumulative well flux constraint is not uncertain - it is just a summation of the specified flux.  So lets give it a crazy small weight, implying it has a tiny uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_std[\"flx_wells_19791230\"] = 1.0e-10\n",
    "pr_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.observation_data.loc[pst.nnz_obs_names,\"weight\"] = pr_std.loc[pst.nnz_obs_names]\n",
    "pst.pestpp_options[\"opt_std_weights\"] = True\n",
    "pst.write(os.path.join(t_d,\"freyberg_opt_uu2.pst\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyemu.os_utils.start_slaves(t_d,\"pestpp-opt\",\"freyberg_opt_uu2.pst\",num_slaves=10,master_dir=m_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par_df = pyemu.pst_utils.read_parfile(os.path.join(m_d,\"freyberg_opt_uu2.1.par\"))\n",
    "print(par_df.loc[dvg_pars,\"parval1\"].sum())\n",
    "par_df.loc[dvg_pars,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Super secret mode\n",
    "\n",
    "turns out, if the opt problem is truely linear, we can reuse results of a previous PESTPP-OPT run to modify lots of the pieces of the optimization problem and resolve without running the model even once!  WAT!?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.copy2(os.path.join(m_d,\"freyberg_opt_uu2.1.jcb\"),os.path.join(m_d,\"restart.jcb\"))\n",
    "shutil.copy2(os.path.join(m_d,\"freyberg_opt_uu2.jcb.1.rei\"),os.path.join(m_d,\"restart.rei\"))\n",
    "\n",
    "pst.pestpp_options[\"base_jacobian\"] = \"restart.jcb\"\n",
    "pst.pestpp_options[\"hotstart_resfile\"] = \"restart.rei\"\n",
    "pst.pestpp_options[\"opt_skip_final\"] = True\n",
    "pst.write(os.path.join(m_d,\"freyberg_opt_restart.pst\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyemu.os_utils.run(\"pestpp-opt freyberg_opt_restart.pst\",cwd=m_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par_df = pyemu.pst_utils.read_parfile(os.path.join(m_d,\"freyberg_opt_restart.1.par\"))\n",
    "print(par_df.loc[dvg_pars,\"parval1\"].sum())\n",
    "par_df.loc[dvg_pars,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh snap!  that means we can do all sort of kewl optimization testing really really fast...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.pestpp_options[\"opt_risk\"] = 0.54\n",
    "pst.write(os.path.join(m_d,\"freyberg_opt_restart.pst\"))\n",
    "pyemu.os_utils.run(\"pestpp-opt freyberg_opt_restart.pst\",cwd=m_d)\n",
    "par_df = pyemu.pst_utils.read_parfile(os.path.join(m_d,\"freyberg_opt_restart.1.par\"))\n",
    "print(par_df.loc[dvg_pars,\"parval1\"].sum())\n",
    "par_df.loc[dvg_pars,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets use the functionality to evaluate how our OUU problem changes if we use posterior standard deviations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_df = pd.read_csv(os.path.join(\"master_ies\",\"freyberg_ies.3.obs.csv\"),index_col=0)\n",
    "pt_std = obs_df.std().loc[pst.nnz_obs_names]\n",
    "pt_std[\"flx_wells_19791230\"] = 1.0e-10\n",
    "pt_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.observation_data.loc[pst.nnz_obs_names,\"weight\"] = pt_std.loc[pst.nnz_obs_names]\n",
    "pst.observation_data.loc[pst.nnz_obs_names,\"weight\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.write(os.path.join(m_d,\"freyberg_opt_restart.pst\"))\n",
    "pyemu.os_utils.run(\"pestpp-opt freyberg_opt_restart.pst\",cwd=m_d)\n",
    "par_df = pyemu.pst_utils.read_parfile(os.path.join(m_d,\"freyberg_opt_restart.1.par\"))\n",
    "print(par_df.loc[dvg_pars,\"parval1\"].sum())\n",
    "par_df.loc[dvg_pars,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = pyemu.pst_utils.read_resfile(os.path.join(m_d,\"freyberg_opt_restart.jcb.1.rei\")).loc[pst.nnz_obs_names,:]\n",
    "res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.pestpp_options[\"opt_risk\"] = 0.95\n",
    "pst.write(os.path.join(m_d,\"freyberg_opt_restart.pst\"))\n",
    "pyemu.os_utils.run(\"pestpp-opt freyberg_opt_restart.pst\",cwd=m_d)\n",
    "par_df = pyemu.pst_utils.read_parfile(os.path.join(m_d,\"freyberg_opt_restart.1.par\"))\n",
    "print(par_df.loc[dvg_pars,\"parval1\"].sum())\n",
    "par_df.loc[dvg_pars,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FINALLY!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now see the reason for high-dimensional uncertainty quantification and history matching: to define and the reduce (through data assimulation) the uncertainty in the model-based constraints so that we can find a 95% risk-averse management solution.  BOOM!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
