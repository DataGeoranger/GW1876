{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PESTPP-GLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will run PESTPP-GLM in standard parameter estimation mode and regularization mode.  In both cases, we will use the baked-in bayes-linear posterior monte carlo analysis to get posterior forecast PDFs.  We will use the prior monte carlo outputs as the prior forecast PDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "plt.rcParams['font.size']=12\n",
    "import flopy\n",
    "import pyemu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_d = \"template\"\n",
    "m_d = \"master_glm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst = pyemu.Pst(os.path.join(t_d,\"freyberg.pst\"))\n",
    "pst.write_par_summary_table(filename=\"none\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reduce the number of adjustable parameters\n",
    "\n",
    "This is the painful part: we cant use 10K+ pars because we cant wait around for that many runs and then the linear algebra of factoring a 10k+ by 10K+ matrix is also difficult.  So that means we need to fix a lot a parameters #frownyface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par = pst.parameter_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid-scale pars\n",
    "gr_pars = par.loc[par.pargp.apply(lambda x: \"gr\" in x),\"parnme\"]\n",
    "par.loc[gr_pars,\"partrans\"] = \"fixed\"\n",
    "pst.npar_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these are the sfr conductance parameters - Ive left all 40 adjustable\n",
    "# but if you uncomment this, it will tie them into 1 parameter effectively\n",
    "# strk_pars = par.loc[par.pargp==\"strk\",\"parnme\"]\n",
    "# p1 = strk_pars.iloc[0]\n",
    "# par.loc[strk_pars.iloc[1:],\"partrans\"] = \"tied\"\n",
    "# par.loc[strk_pars.iloc[1:],\"partied\"] = p1\n",
    "pst.npar_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par.loc[par.pargp.apply(lambda x: \"pp\" in x),\"pargp\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix the storage pilot points - we still have layer-scale storage pars adjustable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#s_pars = par.loc[par.pargp.apply(lambda x: \"pp\" in x and (\"ss\" in x or \"sy\" in x)),\"parnme\"]\n",
    "#par.loc[s_pars,\"partrans\"] = \"fixed\"\n",
    "pst.npar_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_par = par.loc[par.partrans==\"log\",:]\n",
    "adj_par.pargp.value_counts().sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fix the future recharge pilot points, vka in layers 1 and 3 and the initial condition pilot points (we still have layer-scale pars for each of these types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi_grps = [\"pp_rech1\",\"pp_vka0\",\"pp_vka2\",\"pp_strt0\",\"pp_strt1\",\"pp_strt2\"]\n",
    "par.loc[par.pargp.apply(lambda x: x in fi_grps),\"partrans\"] = \"fixed\"\n",
    "pst.npar_adj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, thats better...so lets run PESTPP-GLM.  We will use a single \"base parameter\" jacobian matrix as the basis for 6 super parameter iterations.  Then we will draw 100 realizations from the FOSM posterior parameter covariance matrix and run those 100 realizations to get the psoterior forecast PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.control_data.noptmax = 3\n",
    "pst.pestpp_options[\"n_iter_base\"] = -1\n",
    "pst.pestpp_options[\"n_iter_super\"] = 3\n",
    "pst.pestpp_options[\"num_reals\"] = 50 # this is how many ies uses\n",
    "pst.pestpp_options[\"parcov\"] = \"prior_cov.jcb\"\n",
    "pst.write(os.path.join(t_d,\"freyberg_pp.pst\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyemu.os_utils.start_slaves(t_d,\"pestpp-glm\",\"freyberg_pp.pst\",num_slaves=20,slave_root=\".\",\n",
    "                           master_dir=m_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df=pd.read_csv(os.path.join(m_d,\"freyberg_pp.post.obsen.csv\"),index_col=0)\n",
    "oe = pyemu.ObservationEnsemble.from_dataframe(pst=pst,df=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = oe.phi_vector.hist()#bins=np.linspace(0,100,20))\n",
    "oe.phi_vector.sort_values().iloc[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see the distribution of phi values across the 100 posterior realizations.  Should we accept all of these???  The theoretical phi we should accept is number of nonzero obs (14)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a \"posterior\" ensemble, we need to throw out the realizations with large phi - lets just take the 20 best:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oe_pt = oe.loc[oe.phi_vector.sort_values().index[:20],:] #just take the 20 lowest phi realizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also load and plot the FOSM forecast results along side of the ensemble results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_df = pd.read_csv(os.path.join(m_d,\"freyberg_pp.pred.usum.csv\"),index_col=0)\n",
    "f_df.index = f_df.index.map(str.lower)\n",
    "f_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = pst.observation_data\n",
    "fnames = pst.pestpp_options[\"forecasts\"].split(\",\")\n",
    "for forecast in fnames:\n",
    "    ax = plt.subplot(111)\n",
    "    oe_pt.loc[:,forecast].hist(ax=ax,color=\"b\",alpha=0.5,normed=True)\n",
    "    ax.plot([obs.loc[forecast,\"obsval\"],obs.loc[forecast,\"obsval\"]],ax.get_ylim(),\"r\")\n",
    "    axt = plt.twinx()\n",
    "    x,y = pyemu.plot_utils.gaussian_distribution(f_df.loc[forecast,\"prior_mean\"],f_df.loc[forecast,\"prior_stdev\"])\n",
    "    axt.fill_between(x,0,y,facecolor=\"0.5\",alpha=0.25)\n",
    "    x,y = pyemu.plot_utils.gaussian_distribution(f_df.loc[forecast,\"post_mean\"],f_df.loc[forecast,\"post_stdev\"])\n",
    "    axt.fill_between(x,0,y,facecolor=\"b\",alpha=0.25)\n",
    "    axt.set_ylim(0,axt.get_ylim()[1])\n",
    "    axt.set_yticks([])\n",
    "    ax.set_title(forecast)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup of Tikhonov regularization\n",
    "\n",
    "Now lets setup and use some formal regularization to bring the final phi up to around 14.  We will use first-order regularization based on the covariance matrix we build earlier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov = pyemu.Cov.from_binary(os.path.join(t_d,\"prior_cov.jcb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyemu.helpers.first_order_pearson_tikhonov(pst,cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.prior_information.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.copy2(os.path.join(m_d,\"freyberg_pp.jcb\"),os.path.join(t_d,\"restart_pp.jcb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.pestpp_options[\"base_jacobian\"] = \"restart_pp.jcb\"\n",
    "pst.reg_data.phimlim = pst.nnz_obs\n",
    "pst.reg_data.phimaccept = pst.reg_data.phimlim * 1.1\n",
    "pst.write(os.path.join(t_d,\"freyberg_pp.pst\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyemu.os_utils.start_slaves(t_d,\"pestpp-glm\",\"freyberg_pp.pst\",num_slaves=20,slave_root=\".\",\n",
    "                           master_dir=m_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df=pd.read_csv(os.path.join(m_d,\"freyberg_pp.post.obsen.csv\"),index_col=0)\n",
    "oe = pyemu.ObservationEnsemble.from_dataframe(pst=pst,df=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = oe.phi_vector.hist()#bins=np.linspace(0,100,20))\n",
    "oe.phi_vector.sort_values().iloc[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same as before, to get a \"posterior\" ensemble, we need to throw out the realizations with large phi - lets just take the 20 best:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oe_pt = oe.loc[oe.phi_vector.sort_values().index[:20],:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_df = pd.read_csv(os.path.join(m_d,\"freyberg_pp.pred.usum.csv\"),index_col=0)\n",
    "f_df.index = f_df.index.map(str.lower)\n",
    "f_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = pst.observation_data\n",
    "fnames = pst.pestpp_options[\"forecasts\"].split(\",\")\n",
    "for forecast in fnames:\n",
    "    ax = plt.subplot(111)\n",
    "    oe_pt.loc[:,forecast].hist(ax=ax,color=\"b\",alpha=0.5,normed=True)\n",
    "    ax.plot([obs.loc[forecast,\"obsval\"],obs.loc[forecast,\"obsval\"]],ax.get_ylim(),\"r\")\n",
    "    axt = plt.twinx()\n",
    "    x,y = pyemu.plot_utils.gaussian_distribution(f_df.loc[forecast,\"prior_mean\"],f_df.loc[forecast,\"prior_stdev\"])\n",
    "    axt.fill_between(x,0,y,facecolor=\"0.5\",alpha=0.25)\n",
    "    x,y = pyemu.plot_utils.gaussian_distribution(f_df.loc[forecast,\"post_mean\"],f_df.loc[forecast,\"post_stdev\"])\n",
    "    axt.fill_between(x,0,y,facecolor=\"b\",alpha=0.25)\n",
    "    axt.set_ylim(0,axt.get_ylim()[1])\n",
    "    axt.set_yticks([])\n",
    "    ax.set_title(forecast)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
