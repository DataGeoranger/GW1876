\documentclass[english]{article}
\usepackage[T1]{fontenc}
\usepackage[latin9]{inputenc}
\usepackage{geometry}
\usepackage{amsmath}
\geometry{verbose,tmargin=1.5cm,bmargin=1.5cm,lmargin=1.5cm,rmargin=1.5cm}

\begin{document}
\title{Glossary of important terms for GW1876}
\maketitle

\section*{Notes on mathematics symbology}
It would be really nice if a totally consistent set of symbols was used in the mathematics of parameter estimation and uncertainty analysis. But....no such luck! So many researchers in different fields over a long time have contributed to the work used in this class. As a result, this glossary is an attempt to highlight some general symbology and clarify some terms.

First of all, though, one thing that is consistent (mostly!) is the general linear algebra notation used throughout the class.
\begin{description}
\item[scalar values] Lowercase, non-bold font indicates a scalar (single) value: $x$, $y$, $z$
\item[vectors] Lowercase, bold font indicates a vector of values: $\mathbf{x}$, $\mathbf{y}$, $\mathbf{z}$ 
\item[matrices] Uppercase, bold font indicates a matrix of values: $\mathbf{X}$, $\mathbf{Q}$, $\mathbf{J}$ A matrix with $<\cdot>^{T}$ indicates a matrix transpose. A matrix with $<\cdot>^{-1}$ indicates a matrix inverse.
\item[matrix multiplication] Then, matrix multiplication (with either other matrices or vectors) is expressed simply by adjacent matrices: $\mathbf{Xy}$, $\mathbf{X}^T\mathbf{Q}^{-1}\mathbf{X}$
\end{description}
\section*{Glossary of terms and equations}
\begin{description}
\item [Parameters] Variable input values for models, typically representing system properties and forcings. Values to be estimated in the history matching process. Typically identified as $k$, $p$, or $x$, $\theta$, ($\mathbf{k}$, $\mathbf{p}$, $\boldsymbol{\theta}$ or $\mathbf{x}$ for multiple parameters in a vector).
\item [Observation] Measured system state values. These values are used to compare with model outputs collocated in space and time. The term is often used to mean \emph{both} field measurements and outputs from the model. When referring to a measured value, observations are typically identified by the variables $y$ or $o$  ($\mathbf{y}$ or $\mathbf{o}$ for multiple parameters in a vector)
\item [Modeled Equivalent (aka Simulated Equivalent)] A modeled value collocated in time and space with an observation. There are various ways to identify a single or multiple modeled equivalent values (and, to make things confusing, they are often \emph{also} called ``observations"!)  \newline{}
\textbf{Single values} 
\begin{enumerate}
\item $f\left(x\right)$
\item $X\left(\beta\right)$
\item $M\left(p\right)$
\end{enumerate}
\textbf{Multiple values}
\begin{enumerate}
\item $\mathbf{X}\beta$
\item $\mathbf{M}\mathbf{p}$
\item $\mathbf{NOBS}$ Number of observations/simulated equivalents in the inverse model setup
\item $\mathbf{NPAR}$ Number of adjustable input parameters in the inverse model setup

\end{enumerate}
\item [Forecasts] Model outputs for which field observations are not available. Typically these values are simulated under an uncertain future condition.
\item [Phi] Objective function, defined as the weighted sum of squares of residuals. Phi (aka $\Phi$) is typically calculated as
\begin{equation}
\begin{array}{ccc}
 \Phi=\sum_{i=1}^{n}\left(\frac{y_{i}-f\left(x_{i}\right)}{w_{i}}\right)^{2} & or & \Phi=\left(\mathbf{y}-\mathbf{Jx}\right)^{T}\mathbf{Q}^{-1}\left(\mathbf{y}-\mathbf{Jx}\right)
 \end{array}
\end{equation}
\item [Residuals] The difference between observation values and modeled equivalents $r_i=y_i-f\left(x_i\right)$
\item [Sensitivity] The incremental change of an observation (modeled equivalent, actually) due to an incremental change in a parameter. Typically expressed as a finite-difference approximation of a partial derivative: $\frac{\partial y}{\partial x}$
\item [Jacobian Matrix] A matrix of the sensitivity of all observations in an inverse model to all parameters. This is often shown as a matrix by various names $\mathbf{X}$, $\mathbf{J}$, or $\mathbf{H}$. Each element of the matrix is a single sensitivity value  $\frac{\partial y_i}{\partial x_j}$ for $i\in NOBS$, $j \in NPAR$
\item [Regularization] A preferred condition pertaining to parameters, the deviation from which, elicits a penalty added to the objective function. This serves as a balance between the level of fit or ``measurement Phi"  $(\mathbf{\Phi_M})$ and the coherence with soft knowledge/previous conditions/prior knowledge/regularization $(\mathbf{\Phi_R})$. These terms can also be interpreted as the likelihood function and prior distribution in Bayes' theorem (see below) 
\item [PHIMLIM] A PEST input parameter the governs the strength with which regularization is applied to the objective function. A high value of PHIMLIM indicates a strong penalty for deviation from preferred parameter conditions while a low value of PHIMLIM indicates a weak penalty. The reason this ``dial" is listed as a function of PHIM (e.g. $\mathbf{\Phi_M}$) is because it can then be interpreted as a limit on how well we want to fit the observation data.
\item [FOSM] \emph{fill this in}
\item [Gaussian (multivariate)] The equation for Gaussian (Normal) distribution for a single variable ($x$) is 
\begin{equation}
f(x|\mu,\sigma^2)=\frac{1}{\sqrt{2\pi\sigma^2}}e^{-\frac{1}{2}\frac{\left(x-\mu\right)^2}{\sigma^2}}
\end{equation}
where $\mu$ is the mean and $\sigma$ is the standard deviation
The equation for a multivariate Gaussian for a vector of $k$ variables ($\mathbf{x}$) is
\begin{equation}
f(\mathbf{x} | \mathbf{\mu},\mathbf{\Sigma})=\frac{1}{\sqrt{(2\pi)^k\left|\mathbf{\Sigma}\right|}}e^{-\frac{1}{2}\left( \left(\mathbf{x}-\mathbf{\mu} \right)^T  \mathbf{\Sigma}^{-1}\left(\mathbf{x}-\mathbf{\mu} \right)\right)}
\end{equation}
where $\mu$ is a $k$-length vector of mean values, $\mathbf{\Sigma}$ is the covariance matrix, and $\left|\mathbf{\Sigma}\right|$ is the determinant of the covariance matrix
\item [Weight or Epistemic Uncertainty] A value by which a residual is divided by when constructing the sum of squared residuals. In principal, $w\approx\frac{1}{\sigma}$ where $\sigma$ is an approximation of the expected error between model output and collocated observation values. While the symbol $\sigma$ implies a standard deviation, it is important to note that measurement error only makes up a portion of this error. Other aspects such as structural error (e.g. inadequacy inherent in all models to perfectly simulate the natural world) also contribute to this expected level of error. The reciprocal of weights are also called Epistemic Uncertainty terms.
\item [Weight Covariance matrix (correlation matrix)] In practice, this is usually a $NOBS\times NOBS$ diagonal matrix with values of weights on the diagonal representing the inverse of the observation covariance. This implies a lack of correlation among the observations. A full covariance matrix would indicate correlation among the observations which, in reality, is present but, in practice, is rarely characterized. The weight matrix is often identified as $\mathbf{Q}^{-1}$ or $\mathbf{\Sigma_\epsilon}^{-1}$
\item [Parameter Covariance matrix] The uncertainty of parameters can be expressed as a matrix as well. This is formed also as a diagonal matrix from the bounds around parameter values (assuming that the range between the bounds indicates $4\sigma$ (e.g. 95\% of a normal distribution). In \texttt{pyemu}, some functions accept a \texttt{sigma\_range} argument which can override the $4\sigma$ assumption. In many cases of our applications, parameters are spatially distributed (e.g. hydraulic conductivity fields) so a covariance matrix with off-diagonal terms can be formed to characterize not only their variance but also their correlation/covariance. We often use geostatistical variograms to characterize the covariance of parameters. The parameter covariance matrix is often identified as $C(\mathbf{p})$, $\mathbf{\Sigma_\theta}$, or $\mathbf{R}$.
\item [Measurement noise/error] Measurement noise is a contribution to Epistemic Uncertainty. This is the expected error of repeated measurements due to things like instrument error and also can be compounded by error of surveying a datum, location of an observation on a map, and other factors. 
\item [Structural (model) error] Epistemic uncertainty is actually dominated by structural error relative to measurement noise. The structural error is the expected misfit between measured and modeled values at observation locations due to model inadequacy (including everything from model simplification due to the necessity of discretizing the domain, processes that are missing from the model, etc.)
\item [Monte Carlo Parameter Realization] A set of parameter values, often but not required to be a multi-Gaussian distribution, sampled from the mean values of specified parameter values (either starting values or, in some cases, optimal values following parameter estimation) with covariance from a set of variance values, or a covariance matrix. Can be identified as $\mathbf{\theta}$ 
\item [Monte Carlo Observation Realization] A set of observation values, often but not required to be a multi-Gaussian distribution, sampled using the mean values of measured observations and variance from the observation weight covariance matrix. Can be identified as $\boldsymbol{d_{obs}}$
\item [Monte Carlo Ensemble] A group of realizations of parameters ($\mathbf{\Theta}$), observations ($\mathbf{D_{obs}}$) and the simulated equivalent values $\mathbf{D_{sim}}$. Note that these three matrices are made up of column vectors representing all of the $\boldsymbol{\theta}$, $\mathbf{d_{obs}}$, and  $\mathbf{d_{sim}}$ vectors where $\mathbf{d_{sim}}$ 
\item [Bayes' Theorem] $P\left(\boldsymbol{\theta}|\boldsymbol{D}\right)=\frac{P\left(\textbf{D}|\boldsymbol{\theta}\right) P\left(\boldsymbol{\theta}\right)}{P\left(\textbf{D}\right)}$ ... $\underbrace{P\left(\boldsymbol{\theta}|\textbf{D}\right)}_{\text{posterior pdf}} \propto \underbrace{P\left(\boldsymbol{D}|\boldsymbol{\theta}\right) }_{\text{likelihood function}}\underbrace{P\left(\boldsymbol{\theta}\right)}_{\text{prior pdf}$
\item [Posterior (multivariate distribution)]
\item [Schur Complement]
\item [Prior (multivariate distribution)]
\item [Likelihood (multivariate distribution)] 

\end{description}

\end{document}