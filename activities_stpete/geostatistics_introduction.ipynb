{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyemu\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import geostat_helpers as gh\n",
    "import pandas as pd\n",
    "from scipy.stats.mstats import normaltest\n",
    "import scipy.stats as sps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geostatistics \n",
    "### Some definitions from Geoff Bohling http://people.ku.edu/~gbohling/cpe940/Variograms.pdf\n",
    "> ## “Geostatistics: study of phenomena that vary in space and/or time”\n",
    "(Deutsch, 2002)\n",
    "\n",
    "\n",
    "> ## “Geostatistics can be regarded as a collection of numerical techniques that deal with the characterization of spatial attributes, employing primarily random models in a manner similar to the way in which time series analysis characterizes temporal data.”\n",
    "(Olea, 1999)\n",
    "\n",
    "\n",
    "> ## “Geostatistics offers a way of describing the spatial continuity of natural phenomena and provides adaptations of classical regression techniques to take advantage of this continuity.” \n",
    "(Isaaks and Srivastava, 1989)\n",
    "\n",
    "\n",
    "> ## Geostatistics deals with spatially _autocorrelated_ data.\n",
    "\n",
    "> ## Autocorrelation: correlation between elements of a series and others from the same series separated from them by a given interval. \n",
    "(Oxford American Dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Concepts\n",
    "\n",
    "\n",
    "## 1. Variogram modeling -- a way to characterize spatial correlation\n",
    "## 2. Kriging -- a best linear unbiased estimate (BLUE) for interpolation with minimum variance. There are several flavors - we will focus on Ordinary Kriging\n",
    "## 3. Stochastic Simulation -- http://petrowiki.org/Geostatistical_conditional_simulation\n",
    "## 4. Beyond this multi-Gaussian approach focused on the relationships among pairs of points, there is _multiple point geostatistics_ as well using training images and more complex shapes\n",
    "\n",
    "# These concepts each build on each other. We will briefly touch on the first two"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## let's cook up a quick random field and explore the spatial structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,Y,Z,v,gs,sample_df = gh.data_cooker()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretend (key word!) that this is a hydraulic conductivity field\n",
    "\n",
    "## Any _autocorrelation_ here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gh.grid_plot(X,Y,Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Of course, we would typically only know the values at a few points \n",
    "## (and probably not perfectly)\n",
    "## N.B. --> The default number of samples used here is 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gh.field_scatterplot(sample_df.x,sample_df.y,sample_df.z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "===================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geostatistics is based on a couple main assumptions:\n",
    "   ## 1. The values are second order stationary (the mean and variance are relatively constant) \n",
    "   ## 2. The values are multi-Gaussian (e.g. normally distributed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Are the raw data normally distributed?\n",
    "\n",
    "### Spoiler alert - this field was generated using a variogram!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(Z.ravel(), bins=50)\n",
    "x=np.linspace(70,130,100)\n",
    "plt.plot(x,sps.norm.pdf(x, np.mean(Z),np.std(Z))*len(Z.ravel()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normaltest(Z.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How about our subsample?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(sample_df.z, bins=50)\n",
    "x=np.linspace(70,130,100)\n",
    "plt.plot(x,sps.norm.pdf(x, np.mean(sample_df.z),np.std(sample_df.z))*len(sample_df.z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normaltest(sample_df.z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# That was a pretty small sample....\n",
    "## Explore a bigger sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sample_pts=1000\n",
    "xd = np.random.uniform(0, 1000, n_sample_pts)\n",
    "yd = np.random.uniform(0, 1000, n_sample_pts)\n",
    "z = gh.sample_from_grid(X,Y,Z,xd,yd)\n",
    "plt.hist(z, bins=50)\n",
    "x=np.linspace(70,130,100)\n",
    "plt.plot(x,sps.norm.pdf(x, np.mean(z),np.std(z))*len(z))\n",
    "normaltest(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purity is commendable, but we are going to violate some of these assumptions for sure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "===================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# At the heart of geostatistics is some kind of model expressing the variability of properties in a field\n",
    "\n",
    "## This is a \"variogram\" and we can explore it based on the following empirical formula\n",
    "## $\\hat{\\gamma}\\left(h\\right)=\\frac{1}{2\\left(h\\right)}\\left(z\\left(x_1\\right)-z\\left(x_2\\right)\\right)^2$\n",
    "## where $x_1$ and $x_2$ are the locations of two $z$ data points separated by distance $h$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If we plot these up we get something called a cloud plot showing $\\hat\\gamma$ for all pairs in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h,gam,ax=gh.plot_empirical_variogram(sample_df.x,sample_df.y,sample_df.z,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is pretty messy, so typically it is evaluated in bins, and usually only over half the total possible distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h,gam,ax=gh.plot_empirical_variogram(sample_df.x,sample_df.y,sample_df.z,50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Also note that this was assuming perfect observations. What if there was ~10% noise?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h,gam,ax=gh.plot_empirical_variogram(sample_df.x,sample_df.y,sample_df.z_noisy,30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geostatistics is making the assumption that you can model the variability of this field using a variogram. The variogram is closely related to covariance. \n",
    "\n",
    "## We take advantage of a few assumptions to come up with a few functional forms that should characterize this behavior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `pyemu` supports three variogram models\n",
    "\n",
    "## This follows the _GSLIB_ terminology\n",
    "\n",
    " ## 1. *Spherical*  \n",
    "### $\\gamma\\left(h\\right)=c\\times\\left[1.5\\frac{h}{a}-0.5\\frac{h}{a}^3\\right]$ if $h<a$\n",
    "### $\\gamma\\left(h\\right)=c$ if $h \\ge a$  \n",
    "     \n",
    " ## 2. *Exponential*  \n",
    "### $\\gamma\\left(h\\right)=c\\times\\left[1-\\exp\\left(-\\frac{h}{a}\\right)\\right]$  \n",
    "     \n",
    " ## 3. *Gaussian*  \n",
    "### $\\gamma\\left(h\\right)=c\\times\\left[1-\\exp\\left(-\\frac{h^2}{a^2}\\right)\\right]$  \n",
    "\n",
    "     \n",
    "\n",
    "### $h$ is the separation distance, and $a$ is the range. `contribution` is the variogram value at which the variogram levels off. Also called the `sill`, this value is the maximum variability between points.\n",
    "\n",
    "### The sill is reached at about $a$ for the *Spherical* model, $2a$ for the *Gaussian*, and $3a$ for the *Exponential*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What do these look like?\n",
    "\n",
    "## for a consistent set of parameters:\n",
    "## a=500, c=10\n",
    "## We can use `pyemu` to setup a geostatistical model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=500\n",
    "c=10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up a variogram object and, from that, build a geostatistical structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Spherical_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = pyemu.geostats.SphVario(contribution=c, a=a)\n",
    "gs = pyemu.geostats.GeoStruct(variograms=v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.plot()\n",
    "plt.plot([v.a,v.a],[0,v.contribution],'r')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q= gs.covariance_matrix(X.ravel(), Y.ravel(), names=[str(i) for i in range(len(Y.ravel()))])\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.imshow(Q.x)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Exponential_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = pyemu.geostats.ExpVario(contribution=c, a=a)\n",
    "gs = pyemu.geostats.GeoStruct(variograms=v)\n",
    "gs.plot()\n",
    "plt.plot([v.a,v.a],[0,v.contribution],'r')\n",
    "plt.plot([3*v.a,3*v.a],[0,v.contribution],'r:')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q= gs.covariance_matrix(X.ravel(), Y.ravel(), names=[str(i) for i in range(len(Y.ravel()))])\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.imshow(Q.x)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Gaussian_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = pyemu.geostats.GauVario(contribution=c, a=a)\n",
    "gs = pyemu.geostats.GeoStruct(variograms=v)\n",
    "gs.plot()\n",
    "plt.plot([v.a,v.a],[0,v.contribution],'r')\n",
    "plt.plot([7/4*v.a,7/4*v.a],[0,v.contribution],'r:')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q= gs.covariance_matrix(X.ravel(), Y.ravel(), names=[str(i) for i in range(len(Y.ravel()))])\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.imshow(Q.x)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# If we fit an appropriate model ($\\gamma$) to the empirical variogram ($\\hat\\gamma$), we can use that structure for interpolation from sparse data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h,gam,ax=gh.plot_empirical_variogram(sample_df.x,sample_df.y,sample_df.z,50)\n",
    "new_c=70.0\n",
    "new_a=250.0\n",
    "\n",
    "v_fit = pyemu.geostats.ExpVario(contribution=new_c,a=new_a)\n",
    "gs_fit = pyemu.geostats.GeoStruct(variograms=v_fit)\n",
    "gs_fit.plot(ax=ax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = gs_fit.covariance_matrix(X.ravel(), Y.ravel(), names=[str(i) for i in range(len(Y.ravel()))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "plt.imshow(Q.x)\n",
    "plt.colorbar()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We can perform Kriging to interpolate using this variogram and our \"data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First make an Ordinary Kriging object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = pyemu.geostats.OrdinaryKrige(gs_fit,sample_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next we need to calculate factors (we only do this once - takes a few seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfactors = k.calc_factors(X.ravel(),Y.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## It's easiest to think of these factors as weights on surrounding point to calculate a weighted average of the surrounding values. The weight is a function of the distance - farther points have smaller weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfactors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_interp = gh.geostat_interpolate(X,Y,k.interp_data, sample_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax=gh.grid_plot(X,Y,Z_interp,vlims=[80,135], title='reconstruction')\n",
    "ax.plot(sample_df.x,sample_df.y, 'ko')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gh.grid_plot(X,Y,Z,vlims=[80,135],title='truth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax=gh.grid_plot(X,Y,kfactors.err_var.values.reshape(X.shape), title='Variance of Estimate')\n",
    "ax.plot(sample_df.x,sample_df.y, 'ko')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax=gh.grid_plot(X,Y,np.abs(Z-Z_interp), title='Actual Differences')\n",
    "ax.plot(sample_df.x,sample_df.y, 'yo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What if our data were noisy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h,gam,ax=gh.plot_empirical_variogram(sample_df.x,sample_df.y,sample_df.z_noisy,30)\n",
    "new_c=150.0\n",
    "new_a=275.0\n",
    "\n",
    "# select which kind of variogram here because in reality we don't know, right?\n",
    "v_fit = pyemu.geostats.ExpVario(contribution=new_c,a=new_a)\n",
    "gs_fit = pyemu.geostats.GeoStruct(variograms=v_fit, nugget=50)\n",
    "gs_fit.plot(ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = gs_fit.covariance_matrix(X.ravel(), Y.ravel(), names=[str(i) for i in range(len(Y.ravel()))])\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.imshow(Q.x)\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Again make the Kriging Object and the factors and interpolate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = pyemu.geostats.OrdinaryKrige(gs_fit,sample_df)\n",
    "kfactors = k.calc_factors(X.ravel(),Y.ravel())\n",
    "Z_interp = gh.geostat_interpolate(X,Y,k.interp_data, sample_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax=gh.grid_plot(X,Y,Z_interp,vlims=[80,135], title='reconstruction')\n",
    "ax.plot(sample_df.x,sample_df.y, 'ko')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gh.grid_plot(X,Y,Z,vlims=[80,135],title='truth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax=gh.grid_plot(X,Y,kfactors.err_var.values.reshape(X.shape), title='Variance of Estimate')\n",
    "ax.plot(sample_df.x,sample_df.y, 'ko')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax=gh.grid_plot(X,Y,np.abs(Z-Z_interp), title='Actual Differences')\n",
    "ax.plot(sample_df.x,sample_df.y, 'yo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spectral simulation\n",
    "\n",
    "Because pyemu is pure python (and because the developers are lazy), it only implments spectral simulation for grid-scale field generation.  For regular grids without anisotropy and without conditioning data (\"known\" property values), it is identical to sequential gaussian sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ev = pyemu.geostats.ExpVario(1.0,1)\n",
    "gs = pyemu.geostats.GeoStruct(variograms=ev)\n",
    "ss = pyemu.geostats.SpecSim2d(np.ones(100),np.ones(100),gs)\n",
    "plt.imshow(ss.draw_arrays()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ev = pyemu.geostats.ExpVario(1.0,5)\n",
    "gs = pyemu.geostats.GeoStruct(variograms=ev)\n",
    "ss = pyemu.geostats.SpecSim2d(np.ones(100),np.ones(100),gs)\n",
    "plt.imshow(ss.draw_arrays()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ev = pyemu.geostats.ExpVario(1.0,500)\n",
    "gs = pyemu.geostats.GeoStruct(variograms=ev)\n",
    "ss = pyemu.geostats.SpecSim2d(np.ones(100),np.ones(100),gs)\n",
    "plt.imshow(ss.draw_arrays()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Further resources and information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   # These concepts are used for pilot point interpolation in PEST\n",
    "   ## a. In the GW utilities in PEST (http://www.pesthomepage.org/Groundwater_Utilities.php) \n",
    "   ## b. The main tools are also available in `pyemu` -- we'll use that in the class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A nice but outdated set of references is at: http://people.ku.edu/~gbohling/geostats/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Stanford Geostatistical Modeling Software (SGeMS: http://sgems.sourceforge.net/) is a nice GUI for geostatistical modeling, but it's not being maintained anymore."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `R` has a package: http://rgeostats.free.fr/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some packages are under development in `python` but not very far along. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `QGIS` and `ArcGIS` have some geostatistical modeling capabilities as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
